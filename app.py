import streamlit as st
import logging # Importar a biblioteca de logging

# Configura√ß√£o da p√°gina DEVE SER A PRIMEIRA CHAMADA
st.set_page_config(
    page_title="An√°lise de Rotas Inteligente",
    layout="wide",
    page_icon="üìä"
)

# Restante das importa√ß√µes
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
# Importar matplotlib e seaborn para o heatmap e decomposi√ß√£o
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
import plotly.express as px # Mantido para caso precise em outros lugares (mapa usa go, previs√£o usa go)
import plotly.graph_objects as go
from io import BytesIO
import mysql.connector
import pytz
from pmdarima import auto_arima
from sklearn.metrics import mean_absolute_error
import datetime # Importar datetime para manipular dates
import holidays # Importar a biblioteca holidays para feriados


# Configura√ß√µes de compatibilidade do numpy (manter se for necess√°rio no seu ambiente)
# Isso pode n√£o ser necess√°rio dependendo da vers√£o do numpy, mas √© seguro manter
if np.__version__.startswith('2.'):
    np.float_ = np.float64
    np.int_ = np.int_
    np.bool_ = np.bool_

# Tema personalizado MELHORADO E COERENTE COM FUNDO ESCURO
# Definindo as cores em vari√°veis para f√°cil refer√™ncia
PRIMARY_COLOR = "#00AFFF"         # Azul mais claro e vibrante
BACKGROUND_COLOR = "#1E1E1E"      # Cinza escuro para o fundo principal
SECONDARY_BACKGROUND_COLOR = "#2D2D2D" # Cinza um pouco mais claro para sidebar/elementos
ACCENT_COLOR = "#FF4B4B"          # Vermelho para destaque/alertas
TEXT_COLOR = "#FFFFFF"            # Branco
HEADER_FONT = 'Segoe UI', 'sans-serif' # Fonte

custom_theme = f"""
<style>
:root {{
    --primary-color: {PRIMARY_COLOR};
    --background-color: {BACKGROUND_COLOR};
    --secondary-background-color: {SECONDARY_BACKGROUND_COLOR};
    --accent-color: {ACCENT_COLOR};
    --text-color: {TEXT_COLOR};
    --header-font: {', '.join(HEADER_FONT)};
}}

html, body, [class*="css"] {{
    font-family: var(--header-font);
    color: var(--text-color);
    background-color: var(--background-color);
}}

h1, h2, h3, h4, h5, h6 {{
    color: var(--primary-color);
    font-weight: 600;
}}

/* Ajustar a cor do texto dentro de expanders para melhor contraste */
.stExpander {{
    background-color: var(--secondary-background-color);
    padding: 10px; /* Adiciona um pouco de padding */
    border-radius: 8px;
    margin-bottom: 15px; /* Espa√ßo entre expanders */
}}

.stExpander > div > div > p {{
     color: var(--text-color); /* Garante que o texto dentro do expander seja vis√≠vel */
}}
/* Ajustar cor do header do expander */
.stExpander > div > div > .st-emotion-cache-p5msec {{
    color: var(--text-color); /* Garante que o t√≠tulo do expander seja vis√≠vel */
}}


.stApp {{
    background-color: var(--background-color);
    color: var(--text-color); /* Garante que o texto geral do app use a cor definida */
}}

/* --- Ajustes espec√≠ficos para a sidebar (MAIS AGRESSIVOS) --- */
/* Usando 'background' shorthand e '!important' mais assertivamente */
.stSidebar {{
    background: var(--secondary-background-color) !important; /* For√ßa o fundo escuro */
    color: var(--text-color) !important; /* For√ßa a cor do texto geral */
    /* Adicionar propriedades para garantir que cubra a √°rea corretamente, se necess√°rio */
    /* height: 100vh !important; */
    /* position: fixed !important; width: 210px !important; top: 0; left: 0; */
}}

.stSidebar .stMarkdown {{
     color: var(--text-color) !important; /* For√ßa cor para markdown */
}}

/* For√ßar a cor do texto para elementos de input e labels dentro da sidebar */
.stSidebar label {{
    color: var(--text-color) !important;
}}

.stSidebar div[data-baseweb="select"] > div {{
     background-color: var(--secondary-background-color) !important;
     color: var(--text-color) !important;
     border: 1px solid #555;
}}

.stSidebar input[type="text"],
.stSidebar input[type="date"],
.stSidebar input[type="number"]
{{
    color: var(--text-color) !important;
    background-color: var(--secondary-background-color) !important;
    border: 1px solid #555;
    border-radius: 4px;
    padding: 5px;
}}

.stSidebar .stSlider [data-baseweb="slider"] > div {{
    background-color: var(--primary-color) !important;
}}

.stSidebar .stRadio > label {{
     color: var(--text-color) !important;
}}

/* Garantir que o texto dos bot√µes na sidebar seja vis√≠vel */
.stSidebar button {{
    color: white !important; /* For√ßa a cor do texto do bot√£o para branco */
}}

/* --- Fim ajustes sidebar --- */


.stButton>button {{
    background-color: var(--primary-color);
    color: white;
    border-radius: 8Âêémpx;
    border: none; /* Remover borda padr√£o */
    padding: 10px 20px; /* Padding para melhor apar√™ncia */
    cursor: pointer;
}}

.stButton>button:hover {{
    background-color: #0099E6; /* Cor um pouco mais escura no hover */
}}

.stCheckbox>label {{
    color: var(--text-color);
}}

.stSelectbox>label {{
    color: var(--text-color);
}}
/* Melhorar apar√™ncia do selectbox - Regra global */
.stSelectbox > div[data-baseweb="select"] > div {{
     background-color: var(--secondary-background-color);
     color: var(--text-color);
     border: 1px solid #555;
}}


/* Melhorar apar√™ncia do date input - Regra global */
.stDateInput > label {{
    color: var(--text-color);
}}

.stDateInput input {{
    color: var(--text-color);
    background-color: var(--secondary-background-color);
    border: 1px solid #555; /* Borda sutil */
    border-radius: 4px;
    padding: 5px;
}}

/* Melhorar apar√™ncia do slider - Regra global */
.stSlider > label {{
    color: var(--text-color);
}}

.stSlider [data-baseweb="slider"] > div {{
    background-color: var(--primary-color); /* Cor da barra preenchida */
}}


.stSpinner > div > div {{
    color: var(--primary-color); /* Cor do spinner */
}}

/* Estilo para mensagens de aviso */
.stAlert > div {{
    background-color: rgba(255, 255, 0, 0.1); /* Amarelo semi-transparente */
    color: {TEXT_COLOR};
    border-color: yellow;
}}

/* Estilo para mensagens de erro */
.stAlert[kind="error"] > div {{
    background-color: rgba(255, 0, 0, 0.1); /* Vermelho semi-transparente */
    color: {TEXT_COLOR};
    border-color: red;
}}

/* Estilo para mensagens de sucesso */
.stAlert[kind="success"] > div {{
    background-color: rgba(0, 255, 0, 0.1); /* Verde semi-transparente */
    color: {TEXT_COLOR};
    border-color: green;
}}

/* Adiciona hover effect nos bot√µes */
.stButton button:hover {{
    opacity: 0.9;
    transform: scale(1.02);
    transition: all 0.2s ease-in-out;
}}
/* Ajustar o padding da p√°gina principal */
.stApp > header, .stApp > div {{
    padding-top: 1rem;
    padding-bottom: 1rem;
}}

</style>
"""
st.markdown(custom_theme, unsafe_allow_html=True)


# --- Fun√ß√µes de Banco de Dados e Carga ---

# Use st.secrets para credenciais de banco de dados
# Para configurar: crie um arquivo .streamlit/secrets.toml na raiz do seu projeto
# Exemplo:
# [mysql]
# host = "185.213.81.52"
# user = "u335174317_wazeportal"
# password = "@Ndre2025." # Mude isso para sua senha real ou use secrets
# database = "u335174317_wazeportal"

def get_db_connection():
    """
    Estabelece e retorna uma conex√£o com o banco de dados MySQL.
    A conex√£o √© cacheada pelo Streamlit.
    """
    try:
        # Configura√ß√£o de pooling ou outras otimiza√ß√µes podem ser adicionadas aqui
        conn = mysql.connector.connect(
            host=st.secrets["mysql"]["host"],
            user=st.secrets["mysql"]["user"],
            password=st.secrets["mysql"]["password"],
            database=st.secrets["mysql"]["database"]
        )
        return conn
    except Exception as e:
        logging.exception("Erro ao conectar ao banco de dados:") # Log detalhado
        st.error(f"Erro ao conectar ao banco de dados: {e}")
        st.stop() # Parar a execu√ß√£o se n√£o conseguir conectar

def get_data(start_date=None, end_date=None, route_name=None):
    """
    Busca dados hist√≥ricos de velocidade do banco de dados para uma rota e per√≠odo espec√≠ficos.

    Args:
        start_date (str, optional): Data de in√≠cio no formato YYYY-MM-DD. Defaults to None.
        end_date (str, optional): Data de fim no formato YYYY-MM-DD. Defaults to None.
        route_name (str, optional): Nome da rota. Defaults to None.

    Returns:
        tuple[pd.DataFrame, str | None]: DataFrame com os dados e mensagem de erro (se houver).
    """
    mydb = None
    mycursor = None
    try:
        mydb = get_db_connection()
        mycursor = mydb.cursor()

        query = """
            SELECT hr.route_id, r.name AS route_name, hr.data, hr.velocidade
            FROM historic_routes hr
            JOIN routes r ON hr.route_id = r.id
        """
        conditions = []
        params = []

        if route_name:
            conditions.append("r.name = %s")
            params.append(route_name)
        if start_date:
            conditions.append("hr.data >= %s")
            params.append(start_date)
        if end_date:
             # Para incluir o √∫ltimo dia completo, filtrar por < (data final + 1 dia)
            end_datetime = pd.to_datetime(end_date) + pd.Timedelta(days=1)
            end_date_plus_one_day_str = end_datetime.strftime('%Y-%m-%d')

            conditions.append("hr.data < %s") # Usar o operador MENOR QUE (<)
            params.append(end_date_plus_one_day_str) # Usar a data final + 1 dia

        if conditions:
            query += " WHERE " + " AND ".join(conditions)

        query += " ORDER BY hr.data ASC"

        mycursor.execute(query, params)
        results = mycursor.fetchall()
        col_names = [desc[0] for desc in mycursor.description]
        df = pd.DataFrame(results, columns=col_names)

        # Convertendo 'data' para datetime e 'velocidade' para num√©rico
        df['data'] = pd.to_datetime(df['data']).dt.tz_localize(None) # Remover timezone se presente
        df['velocidade'] = pd.to_numeric(df['velocidade'], errors='coerce')

        return df, None
    except Exception as e:
        logging.exception(f"Erro ao obter dados para rota {route_name}:") # Log detalhado
        return pd.DataFrame(), str(e) # Retorna DataFrame vazio e erro
    finally:
        if mycursor:
            mycursor.close()
        # N√£o feche a conex√£o 'mydb' aqui, pois ela √© gerenciada por st.cache_resource

def get_all_route_names():
    """
    Busca todos os nomes de rotas distintos no banco de dados.
    A lista de nomes √© cacheada pelo Streamlit.

    Returns:
        list[str]: Lista de nomes de rotas.
    """
    mydb = None
    mycursor = None
    try:
        mydb = get_db_connection()
        mycursor = mydb.cursor()
        query = "SELECT DISTINCT name FROM routes"
        mycursor.execute(query)
        results = mycursor.fetchall()
        return [row[0] for row in results]
    except Exception as e:
        logging.exception("Erro ao obter nomes das rotas:") # Log detalhado
        st.error(f"Erro ao obter nomes das rotas: {e}")
        return []
    finally:
        if mycursor:
            mycursor.close()
        # N√£o feche a conex√£o 'mydb' aqui, pois ela √© gerenciada por st.cache_resource

def get_route_coordinates(route_id):
    """
    Busca as coordenadas geogr√°ficas (linha) para uma rota espec√≠fica.
    As coordenadas s√£o cacheadas pelo Streamlit.

    Args:
        route_id (int): ID da rota.

    Returns:
        pd.DataFrame: DataFrame com colunas 'longitude' e 'latitude'.
    """
    mydb = None
    mycursor = None
    try:
        mydb = get_db_connection()
        mycursor = mydb.cursor()
        query = "SELECT x, y FROM route_lines WHERE route_id = %s ORDER BY id"
        mycursor.execute(query, (route_id,))
        results = mycursor.fetchall()
        df = pd.DataFrame(results, columns=['longitude', 'latitude'])
        return df
    except Exception as e:
        logging.exception(f"Erro ao obter coordenadas para route_id {route_id}:") # Log detalhado
        st.error(f"Erro ao obter coordenadas: {e}")
        return pd.DataFrame()
    finally:
        if mycursor:
            mycursor.close()
        # N√£o feche a conex√£o 'mydb' aqui, pois ela √© gerenciada por st.cache_resource

# --- Fun√ß√µes de Processamento e An√°lise ---

def clean_data(df):
    """
    Limpa, interpola e adiciona features temporais a um DataFrame de velocidade.

    Args:
        df (pd.DataFrame): DataFrame bruto com colunas 'data' e 'velocidade'.

    Returns:
        pd.DataFrame: DataFrame limpo com 'day_of_week' e 'hour' adicionados.
                      Retorna DataFrame vazio se todas as velocidades forem nulas.
    """
    if df.empty:
        return pd.DataFrame()

    df = df.copy()

    # Adicionar valida√ß√£o de dados: verificar se todas as velocidades est√£o nulas
    if df['velocidade'].isnull().all():
        st.warning("Ap√≥s o carregamento, todas as velocidades est√£o nulas. Verifique os dados de origem ou o per√≠odo selecionado.")
        return pd.DataFrame() # Retorna DataFrame vazio se todos os valores s√£o nulos

    # Assume que o DataFrame j√° est√° filtrado pela rota e per√≠odo
    # e que a coluna 'data' j√° √© datetime sem timezone e 'velocidade' √© num√©rica
    df = df.sort_values('data')
    df['velocidade'] = (
        df['velocidade']
        .clip(upper=150) # Limita a velocidade a 150 km/h
        .interpolate(method='linear') # Interpola valores ausentes linearmente
        .ffill() # Preenche valores restantes com o √∫ltimo valor v√°lido
        .bfill() # Preenche valores restantes com o pr√≥ximo valor v√°lido
    )
    # Recalcular dia da semana e hora ap√≥s interpola√ß√£o/limpeza, se necess√°rio
    # Usar locale para nomes dos dias em portugu√™s
    # import locale
    # locale.setlocale(locale.LC_TIME, 'pt_BR.UTF8') # Configurar localidade (pode precisar instalar no ambiente)
    df['day_of_week'] = df['data'].dt.day_name() # Retorna em ingl√™s por padr√£o, mapearemos para o heatmap
    df['hour'] = df['data'].dt.hour
    return df.dropna(subset=['velocidade']) # Remove linhas onde a velocidade ainda √© NaN


def seasonal_decomposition_plot(df):
    """
    Realiza e plota a decomposi√ß√£o sazonal de uma s√©rie temporal de velocidade.

    Args:
        df (pd.DataFrame): DataFrame com dados limpos e √≠ndice de tempo.
    """
    if df.empty:
        st.info("N√£o h√° dados para realizar a decomposi√ß√£o sazonal.")
        return

    # Garantir frequ√™ncia temporal, interpolando se houver lacunas curtas
    # Usa a coluna 'data' como √≠ndice e define a frequ√™ncia como 3 minutos
    df_ts = df.set_index('data')['velocidade'].asfreq('3min')

    # Interpolar apenas se houver dados suficientes ap√≥s asfreq
    # Verifica a propor√ß√£o de NaNs antes de interpolar
    if df_ts.isnull().sum() / len(df_ts) > 0.2: # Exemplo: Se mais de 20% dos dados s√£o NaN ap√≥s asfreq
         st.warning("Muitos dados faltantes ou espa√ßados para interpola√ß√£o e decomposi√ß√£o sazonal confi√°veis.")
         return

    df_ts = df_ts.interpolate(method='time')

    # O per√≠odo para sazonalidade di√°ria em dados de 3 em 3 minutos √© 480 (24 horas * 60 min / 3 min)
    period = 480 # Usando o per√≠odo padr√£o

    # Precisa de pelo menos 2 ciclos completos de dados para decomposi√ß√£o sazonal
    if len(df_ts.dropna()) < 2 * period:
         st.warning(f"Dados insuficientes para decomposi√ß√£o sazonal com per√≠odo de {period}. Necess√°rio pelo menos {2*period} pontos de dados v√°lidos.")
         return

    try:
        # model='additive' √© geralmente adequado para velocidade onde as varia√ß√µes s√£o mais constantes
        decomposition = seasonal_decompose(df_ts.dropna(), model='additive', period=period)
        fig, ax = plt.subplots(4, 1, figsize=(12, 10)) # Adiciona componente de Res√≠duo
        decomposition.observed.plot(ax=ax[0], title='Observado')
        decomposition.trend.plot(ax=ax[1], title='Tend√™ncia')
        decomposition.seasonal.plot(ax=ax[2], title=f'Sazonalidade (Periodo {period})')
        decomposition.resid.plot(ax=ax[3], title='Res√≠duo')
        plt.tight_layout()

        # Configurar cores dos eixos e t√≠tulos para o tema escuro
        for a in ax:
            a.tick_params(axis='x', colors=TEXT_COLOR)
            a.tick_params(axis='y', colors=TEXT_COLOR)
            a.title.set_color(TEXT_COLOR)
            a.xaxis.label.set_color(TEXT_COLOR)
            a.yaxis.label.set_color(TEXT_COLOR)
            # Fundo dos subplots
            a.set_facecolor(SECONDARY_BACKGROUND_COLOR)

        # Configurar cor de fundo da figura
        fig.patch.set_facecolor(SECONDARY_BACKGROUND_COLOR)

        st.pyplot(fig)
    except Exception as e:
         logging.exception("Erro ao realizar decomposi√ß√£o sazonal:") # Log detalhado
         st.warning(f"N√£o foi poss√≠vel realizar a decomposi√ß√£o sazonal: {e}")
         st.info("Verifique se os dados t√™m uma frequ√™ncia regular ou se h√° dados suficientes.")


def create_holiday_exog(index):
    """
    Cria features ex√≥genas bin√°rias ('is_holiday' e 'is_pre_holiday') para um DateTimeIndex.

    Args:
        index (pd.DateTimeIndex): √çndice de tempo para o qual gerar as features.

    Returns:
        pd.DataFrame: DataFrame com as colunas 'is_holiday' e 'is_pre_holiday'.
    """
    if index.empty:
        return pd.DataFrame(index=index)

    # Obter feriados brasileiros para os anos presentes no √≠ndice
    br_holidays = holidays.CountryHoliday('BR', years=index.year.unique())
    exog_df = pd.DataFrame(index=index)

    # is_holiday: Verifica se a data do timestamp atual √© um feriado
    exog_df['is_holiday'] = index.to_series().apply(lambda date: date.date() in br_holidays).astype(int)

    # is_pre_holiday: Verifica se a data EXATAMENTE 24 horas a partir do timestamp atual √© um feriado,
    # E a data atual N√ÉO √© um feriado.
    # Isso requer que o √≠ndice tenha uma frequ√™ncia regular definida por asfreq.
    if index.freq is None:
         # Fallback para frequ√™ncia irregular - verifica se o pr√≥ximo dia CALENDAR (24h) √© um feriado
         exog_df['is_pre_holiday'] = index.to_series().apply(
             lambda date: (date + pd.Timedelta(days=1)).date() in br_holidays and date.date() not in br_holidays
         ).astype(int)
    else:
        # Usa a frequ√™ncia para calcular um offset exato de 24 horas
        one_day_offset = pd.Timedelta(days=1)
        # Cria uma s√©rie de dates exatamente 24 horas no futuro com base na frequ√™ncia do √≠ndice
        dates_in_24h = index + one_day_offset
        # Verifica se a data 24 hours later √© um feriado
        is_next_day_holiday = dates_in_24h.to_series().apply(lambda date: date.date() in br_holidays).astype(int)
        # Uma data √© v√©spera de feriado se a data 24h later √© feriado E a data atual N√ÉO √© feriado
        exog_df['is_pre_holiday'] = is_next_day_holiday & (exog_df['is_holiday'] == 0)

    return exog_df


# Fun√ß√£o de previs√£o ARIMA (revisada para usar intervalos de confian√ßa e tratamento de dados E EXOG)
# N√£o cacheamos previs√µes pois elas dependem de dados recentes e podem ser acionadas pelo usu√°rio
# @st.cache_data # N√£o use cache_data para previs√µes se elas devem ser geradas sob demanda
def create_arima_forecast(df, route_id, steps=10, m_period=480):
    """
    Cria e executa um modelo de previs√£o ARIMA sazonal com vari√°veis ex√≥genas (feriados/v√©speras).

    Args:
        df (pd.DataFrame): DataFrame com dados hist√≥ricos de velocidade limpos.
        route_id (int): ID da rota.
        steps (int, optional): N√∫mero de passos futuros para prever. Defaults to 10.
        m_period (int, optional): Per√≠odo sazonal para o auto_arima. Defaults to 480 (di√°rio @ 3min).

    Returns:
        pd.DataFrame: DataFrame com a previs√£o (datas, yhat, limites de confian√ßa) ou DataFrame vazio em caso de falha.
    """
    if df.empty:
        # Mensagem j√° exibida na chamada
        return pd.DataFrame()

    # Preparar dados para auto_arima (j√° vem limpo)
    # Garantir frequ√™ncia temporal, interpolando se houver lacunas curtas
    arima_data_full = df.set_index('data')['velocidade'].asfreq('3min').dropna()

    # Criar features ex√≥genas (feriados e v√©speras) para o per√≠odo dos dados hist√≥ricos
    exog_data_full = create_holiday_exog(arima_data_full.index)

    # Alinhar dados da s√©rie temporal (y) e dados ex√≥genos (X) usando um join interno
    # Isso garante que temos 'y' e 'X' para os mesmos timestamps
    combined_df = arima_data_full.to_frame(name='y').join(exog_data_full, how='inner').dropna()
    arima_data = combined_df['y']
    exog_data = combined_df[['is_holiday', 'is_pre_holiday']]


    # Precisa de dados suficientes para o modelo sazonal ARIMA
    # Um m√≠nimo de 2-3 ciclos sazonais √© recomendado
    min_data_points = 2 * m_period # M√≠nimo 2 ciclos completos para detectar sazonalidade

    if len(arima_data) < min_data_points:
         st.warning(f"Dados insuficientes ({len(arima_data)} pontos) para treinar um modelo de previs√£o ARIMA sazonal robusto com per√≠odo {m_period}. Necess√°rio pelo menos {int(min_data_points)} pontos v√°lidos ap√≥s alinhamento.")
         return pd.DataFrame()

    try:
        # auto_arima encontrar√° os melhores par√¢metros p,d,q,P,D,Q
        # Passando o per√≠odo sazonal 'm' selecionado pelo usu√°rio
        # PASSANDO DADOS EX√ìGENOS (X=exog_data)
        with st.spinner(f"Treinando modelo ARIMA para a rota {route_id} com per√≠odo sazonal m={m_period}..."):
             model = auto_arima(arima_data, X=exog_data, seasonal=True, m=m_period,
                                error_action='ignore', suppress_warnings=True,
                                stepwise=True, random_state=42,
                                n_fits=20) # Limitar o n√∫mero de fits para evitar tempo excessivo

        # Gerar dates futuras com base na √∫ltima data hist√≥rica e frequ√™ncia
        last_date = arima_data.index.max()
        # A frequ√™ncia deve ser compat√≠vel com m=480 ou 3360 (baseado em 3min)
        freq_str = '3min' # Assumindo 3minutos como base

        future_dates = pd.date_range(start=last_date, periods=steps + 1, freq=freq_str)[1:]

        # Criar features ex√≥genas (feriados e v√©speras) para o PER√çODO DA PREVIS√ÉO
        future_exog_data = create_holiday_exog(future_dates)
        # Garantir que o √≠ndice dos dados ex√≥genos futuros corresponda exatamente √†s dates futuras
        future_exog_data = future_exog_data.reindex(future_dates)


        # Realizar a previs√£o com intervalos de confian√ßa
        # PASSANDO DADOS EX√ìGENOS FUTUROS (X=future_exog_data)
        forecast, conf_int = model.predict(n_periods=steps, return_conf_int=True, X=future_exog_data)


        forecast_df = pd.DataFrame({
            'ds': future_dates,
            'yhat': forecast,
            'yhat_lower': conf_int[:, 0], # Limite inferior do intervalo de confian√ßa
            'yhat_upper': conf_int[:, 1], # Limite superior do intervalo de confian√ßa
            'id_route': route_id
        })

        # Garante que as previs√µes e intervalos de confian√ßa n√£o s√£o negativos
        forecast_df[['yhat', 'yhat_lower', 'yhat_upper']] = forecast_df[['yhat', 'yhat_lower', 'yhat_upper']].clip(lower=0)

        return forecast_df
    except Exception as e:
        logging.exception("Erro durante o treinamento ou previs√£o do modelo ARIMA:") # Log detalhado
        st.error(f"Erro durante o treinamento ou previs√£o do modelo ARIMA: {str(e)}")
        st.info("Verifique os dados de entrada, a quantidade de dados, ou a configura√ß√£o do modelo ARIMA.")
        return pd.DataFrame()


def save_forecast_to_db(forecast_df):
    """
    Salva um DataFrame de previs√£o no banco de dados.

    Args:
        forecast_df (pd.DataFrame): DataFrame com a previs√£o a ser salva.
    """
    if forecast_df.empty:
        st.warning("N√£o h√° previs√£o para salvar no banco de dados.")
        return # N√£o salva se o DataFrame estiver vazio

    # Ajustar nomes de colunas para corresponder √† tabela forecast_history
    # Assumindo que a tabela forecast_history tem colunas como 'data', 'previsao', 'limite_inferior', 'limite_superior', 'id_rota'
    forecast_df_mapped = forecast_df.rename(columns={
        'ds': 'data',
        'yhat': 'previsao',
        'yhat_lower': 'limite_inferior',
        'yhat_upper': 'limite_superior',
        'id_route': 'id_rota'
    })

    # Selecionar apenas as colunas que voc√™ quer salvar
    cols_to_save = ['data', 'previsao', 'limite_inferior', 'limite_superior', 'id_rota']
    forecast_df_mapped = forecast_df_mapped[cols_to_save]

    try:
        # st.info("Conectando ao banco de dados para salvar previs√£o...") # Substitu√≠do por toast/log
        # Usando credenciais do secrets
        engine = create_engine(
            f'mysql+mysqlconnector://{st.secrets["mysql"]["user"]}:{st.secrets["mysql"]["password"]}@{st.secrets["mysql"]["host"]}/{st.secrets["mysql"]["database"]}'
        )
        # Usando o gerenciador de contexto do SQLAlchemy para garantir commit/rollback e fechar a conex√£o
        # if_exists='append' adiciona novas linhas. Se voc√™ precisar evitar duplicatas,
        # pode precisar de uma l√≥gica de upsert ou verificar antes de inserir.
        with engine.begin() as connection:
             # st.info("Salvando previs√£o na tabela forecast_history...") # Substitu√≠do por toast/log
             # Converte datetime para tipo compat√≠vel com SQL, como string ou timestamp
             forecast_df_mapped['data'] = forecast_df_mapped['data'].dt.strftime('%Y-%m-%d %H:%M:%S')
             forecast_df_mapped.to_sql('forecast_history', con=connection, if_exists='append', index=False)
             st.toast("Previs√£o salva no banco de dados!", icon="‚úÖ") # Feedback ao usu√°rio com toast
    except Exception as e:
        logging.exception("Erro ao salvar previs√£o no banco de dados:") # Log detalhado
        st.error(f"Erro ao salvar previs√£o no banco de dados: {e}")


def gerar_insights(df):
    """
    Gera insights autom√°ticos sobre a velocidade m√©dia, dia mais lento, etc.

    Args:
        df (pd.DataFrame): DataFrame com dados hist√≥ricos de velocidade processados.

    Returns:
        str: String formatada com os insights.
    """
    insights = []
    if df.empty:
        return "N√£o h√° dados para gerar insights neste per√≠odo."

    media_geral = df['velocidade'].mean()
    insights.append(f"üìå Velocidade m√©dia geral: **{media_geral:.2f} km/h**")

    # Encontrar o dia (data espec√≠fica) com a menor velocidade m√©dia dentro do per√≠odo selecionado
    if 'data' in df.columns and not df['data'].empty:
        # Agrupar por data (apenas a parte da data)
        daily_avg = df.groupby(df['data'].dt.date)['velocidade'].mean()
        if not daily_avg.empty:
            dia_mais_lento_date = daily_avg.idxmin()
            velocidade_dia_mais_lento = daily_avg.min()
            insights.append(f"üìÖ Dia com a menor velocidade m√©dia: **{dia_mais_lento_date.strftime('%d/%m/%Y')}** ({velocidade_dia_mais_lento:.2f} km/h)")
        else:
             insights.append("N√£o foi poss√≠vel calcular a velocidade m√©dia di√°ria.")
    else:
         insights.append("Coluna 'data' n√£o encontrada ou vazia no DataFrame para insights di√°rios.")


    # Encontrar o dia da semana mais lento em m√©dia
    if 'day_of_week' in df.columns and not df['day_of_week'].empty:
            weekday_avg = df.groupby('day_of_week')['velocidade'].mean()
            if not weekday_avg.empty:
                # Mapeamento para portugu√™s e ordena√ß√£o
                dias_pt_map = {
                    'Monday': 'Segunda-feira', 'Tuesday': 'Ter√ßa-feira', 'Wednesday': 'Quarta-feira',
                    'Thursday': 'Quinta-feira', 'Friday': 'Sexta-feira', 'Saturday': 'S√°bado', 'Sunday': 'Domingo'
                }
                weekday_avg_pt = weekday_avg.rename(index=dias_pt_map) # <-- Esta √© a linha 662 corrigida
                dias_ordenados_pt = ['Segunda-feira', 'Ter√ßa-feira', 'Quarta-feira', 'Quinta-feira', 'Sexta-feira', 'S√°bado', 'Domingo']
                weekday_avg_pt = weekday_avg_pt.reindex(dias_ordenados_pt)

                dia_da_semana_mais_lento = weekday_avg_pt.idxmin()
                insights.append(f"üóìÔ∏è Dia da semana mais lento (em m√©dia): **{dia_da_semana_mais_lento}**")
            else:
                insights.append("N√£o foi poss√≠vel calcular a velocidade m√©dia por dia da semana.")
    else:
        insights.append("Coluna 'day_of_week' n√£o encontrada ou vazia no DataFrame para insights por dia da semana.")

    # Encontrar a hora do dia mais lenta em m√©dia
    if 'hour' in df.columns and not df['hour'].empty:
        hourly_avg = df.groupby('hour')['velocidade'].mean()
        if not hourly_avg.empty:
            hora_mais_lenta = hourly_avg.idxmin()
            insights.append(f"üïí Hora do dia mais lenta (em m√©dia): **{hora_mais_lenta:02d}:00**")
        else:
             insights.append("N√£o foi poss√≠vel calcular a velocidade m√©dia por hora do dia.")
    else:
         insights.append("Coluna 'hour' n√£o encontrada ou vazia no DataFrame para insights por hora.")


    return "\n\n".join(insights)

def get_route_metadata():
    """
    Busca metadados completos das rotas incluindo dados hist√≥ricos e atuais.
    """
    mydb = None
    mycursor = None
    try:
        mydb = get_db_connection()
        mycursor = mydb.cursor()
        query = """
            SELECT 
                id, name, jam_level, 
                avg_speed, avg_time,
                historic_speed, historic_time 
            FROM routes
            WHERE is_active = 1
        """
        mycursor.execute(query)
        results = mycursor.fetchall()
        col_names = [desc[0] for desc in mycursor.description]
        df = pd.DataFrame(results, columns=col_names)
        return df
    except Exception as e:
        logging.exception("Erro ao obter metadados das rotas:")
        return pd.DataFrame()

def analyze_current_vs_historical(metadata_df):
    """
    Analisa os dados atuais vs hist√≥ricos e gera insights.
    Retorna DataFrame com m√©tricas calculadas.
    """
    analysis_df = metadata_df.copy()
    
    # Calcular varia√ß√µes percentuais
    analysis_df['var_time'] = ((analysis_df['avg_time'] - analysis_df['historic_time']) / analysis_df['historic_time']) * 100
    analysis_df['var_speed'] = ((analysis_df['avg_speed'] - analysis_df['historic_speed']) / analysis_df['historic_speed']) * 100
    
    # Classificar status
    analysis_df['status'] = np.where(
        (analysis_df['var_time'] > 15) | (analysis_df['var_speed'] < -15),
        'Cr√≠tico',
        np.where(
            (analysis_df['var_time'] > 5) | (analysis_df['var_speed'] < -5),
            'Aten√ß√£o',
            'Normal'
        )
    )


# --- Fun√ß√£o Principal do Aplicativo Streamlit ---

def main():
    """
    Fun√ß√£o principal que configura a interface do Streamlit, carrega dados
    e exibe an√°lises e previs√µes.
    """
    # Verificar se as secrets do banco de dados est√£o configuradas
    if "mysql" not in st.secrets or not all(k in st.secrets["mysql"] for k in ("host", "user", "password", "database")):
        st.error("As credenciais do banco de dados n√£o foram configuradas corretamente no secrets.toml.")
        st.markdown("Por favor, crie ou atualize o arquivo `.streamlit/secrets.toml` na raiz do seu projeto com as informa√ß√µes de conex√£o do MySQL.")
        logging.error("Secrets do banco de dados n√£o configuradas.") # Log detalhado
        st.stop() # Parar a execu√ß√£o


    with st.sidebar:
        st.title("‚ÑπÔ∏è Painel de Controle")
        st.markdown("""
            Configure a an√°lise de rotas aqui.

            **Funcionalidades:**
            - Visualize dados hist√≥ricos de velocidade
            - Detecte padr√µes de tr√°fego (heatmap, decomposi√ß√£o)
            - Obtenha insights autom√°ticos sobre a rota
            - Previs√£o de velocidade para o futuro pr√≥ximo
            - Compare a an√°lise entre diferentes rotas
        """)

        st.subheader("Sele√ß√£o de Rotas")
        # Carregar nomes das rotas de forma eficiente (cached)
        all_route_names = get_all_route_names()
        if not all_route_names:
             st.warning("N√£o foi poss√≠vel carregar os nomes das rotas do banco de dados ou n√£o h√° rotas dispon√≠veis.")
             logging.warning("Nenhum nome de rota encontrado no banco de dados.") # Log detalhado
             st.stop() # Parar se n√£o houver rotas

        # Usar √≠ndice para garantir que o selectbox n√£o quebre se o nome da rota mudar ou n√£o existir
        # Usar session_state para persistir a sele√ß√£o de rota
        if "main_route_select" not in st.session_state or st.session_state.main_route_select not in all_route_names:
             st.session_state.main_route_select = all_route_names[0]

        try:
            default_main_route_index = all_route_names.index(st.session_state.main_route_select)
        except ValueError:
             default_main_route_index = 0

        route_name = st.selectbox(
            "Rota Principal:",
            all_route_names,
            index=default_main_route_index,
            key="main_route_select_box" # Use um key diferente do session_state key
        )
        # Atualiza o session_state key ap√≥s o selectbox
        st.session_state.main_route_select = route_name


        compare_enabled = st.checkbox("Comparar com outra rota", key="compare_checkbox")
        second_route = None
        if compare_enabled:
            available_for_comparison = [r for r in all_route_names if r != route_name]
            if available_for_comparison:
                 # Usar session_state para persistir a sele√ß√£o da rota secund√°ria
                 if "secondary_route_select" not in st.session_state or st.session_state.secondary_route_select not in available_for_comparison:
                      st.session_state.secondary_route_select = available_for_comparison[0]

                 try:
                     default_secondary_route_index = available_for_comparison.index(st.session_state.secondary_route_select)
                 except ValueError:
                      default_secondary_route_index = 0

                 second_route = st.selectbox(
                     "Rota Secund√°ria:",
                     available_for_comparison,
                     index=default_secondary_route_index,
                     key="secondary_route_select_box" # Use um key diferente do session_state key
                 )
                 # Atualiza o session_state key
                 st.session_state.secondary_route_select = second_route

            else:
                 st.info("N√£o h√° outras rotas dispon√≠veis para compara√ß√£o.")
                 compare_enabled = False # Desabilita compara√ß√£o se n√£o houver outras rotas


        st.subheader("Per√≠odo de An√°lise")
        # Usar um seletor de data por rota para flexibilidade na compara√ß√£o de per√≠odos diferentes
        # Usar session_state para persistir as dates
        today = datetime.date.today()
        week_ago = today - datetime.timedelta(days=7)

        col_date1, col_date2 = st.columns(2)
        with col_date1:
             # Initialize session state for date range if not exists
             if f"date_range_{route_name}" not in st.session_state:
                 st.session_state[f"date_range_{route_name}"] = (week_ago, today)

             date_range_main_input = st.date_input(
                 f"Per√≠odo para '{route_name}'",
                 value=st.session_state[f"date_range_{route_name}"],
                 max_value=today,
                 key=f"date_range_{route_name}_input" # Use um key diferente
             )
             # Update session state
             st.session_state[f"date_range_{route_name}"] = date_range_main_input
             date_range_main = st.session_state[f"date_range_{route_name}"] # Use o valor persistido


        date_range_secondary = None
        if compare_enabled and second_route:
             with col_date2:
                 # Initialize session state for date range if not exists
                 if f"date_range_{second_route}" not in st.session_state:
                      st.session_state[f"date_range_{second_route}"] = (week_ago, today)

                 date_range_secondary_input = st.date_input(
                      f"Per√≠odo para '{second_route}'",
                      value=st.session_state[f"date_range_{second_route}"],
                      max_value=today,
                      key=f"date_range_{second_route}_input" # Use um key diferente
                 )
                 # Update session state
                 st.session_state[f"date_range_{second_route}"] = date_range_secondary_input
                 date_range_secondary = st.session_state[f"date_range_{second_route}"] # Use o valor persistido


        # Validar as dates
        if date_range_main and date_range_main[0] > date_range_main[1]:
            st.error("Data final da rota principal n√£o pode ser anterior √† data inicial")
            st.stop()
        if compare_enabled and date_range_secondary and date_range_secondary[0] > date_range_secondary[1]:
             st.error("Data final da rota secund√°ria n√£o pode ser anterior √† data inicial.")
             st.stop()

        st.subheader("Configura√ß√µes ARIMA")
        # Adicionar seletor para o per√≠odo sazonal (m)
        m_period_options = {
            "Di√°rio (480 pontos @ 3min)": 480,
            "Semanal (3360 pontos @ 3min)": 3360,
            "Mensal (~14400 pontos @ 3min)": 14400 # Aproximado
        }
        selected_m_key = st.selectbox(
            "Per√≠odo sazonal (m) para ARIMA:",
            list(m_period_options.keys()),
            index=0, # Padr√£o di√°rio
            key="arima_m_select"
        )
        arima_m_period = m_period_options[selected_m_key]

        # Adicionar controle para o n√∫mero de passos da previs√£o
        forecast_steps = st.slider(f"Quantos pontos futuros prever ({arima_m_period} / freq 3min)?",
                                   min_value=1, max_value=4 * arima_m_period, # Permite prever at√© 4 ciclos
                                   value=arima_m_period // 2, # Padr√£o: meio ciclo
                                   step=int(arima_m_period / 10), # Passo razo√°vel (1/10 do ciclo)
                                   key="forecast_steps_slider")
        st.info(f"Previs√£o cobrir√° aproximadamente {forecast_steps * 3} minutos.")


    st.title("üöÄ An√°lise de Rotas Inteligente")
    st.markdown("Selecione as rotas e o per√≠odo de an√°lise no painel lateral.")

    routes_info = {}
    routes_to_process = [route_name]
    if compare_enabled and second_route:
        routes_to_process.append(second_route)

    # --- Carregamento e Processamento de Dados ---
    st.header("‚è≥ Processando Dados...")
    processed_dfs = {} # Dicion√°rio para armazenar os DataFrames processados

    for route in routes_to_process:
        date_range = date_range_main if route == route_name else date_range_secondary
        if date_range is None: # Caso a compara√ß√£o esteja habilitada, mas a rota secund√°ria n√£o tenha range
             continue

        # Converter objetos date para stringsYYYY-MM-DD para passar para get_data
        start_date_str = date_range[0].strftime('%Y-%m-%d')
        end_date_str = date_range[1].strftime('%Y-%m-%d')

        with st.spinner(f'Carregando e processando dados para {route} de {start_date_str} a {end_date_str}...'):
            # Carregar dados filtrando por nome da rota e per√≠odo (cached)
            raw_df, error = get_data(
                start_date=start_date_str,
                end_date=end_date_str,
                route_name=route
            )

            if error:
                 st.error(f"Erro ao carregar dados para {route}: {error}")
                 logging.error(f"Erro ao carregar dados para {route}: {error}")
                 routes_info[route] = {'data': pd.DataFrame(), 'id': None, 'error': error}
                 continue # Pula para a pr√≥xima rota se houver erro

            if raw_df.empty:
                st.warning(f"Nenhum dado encontrado para a rota '{route}' no per√≠odo de {start_date_str} a {end_date_str}. Por favor, ajuste o intervalo de dates.")
                logging.warning(f"Nenhum dado encontrado para a rota '{route}' no per√≠odo {start_date_str} a {end_date_str}.")
                routes_info[route] = {'data': pd.DataFrame(), 'id': None}
                continue # Pula para a pr√≥xima rota

            # Adicionar indicador de qualidade dos dados (dados ausentes)
            total_records = len(raw_df)
            initial_nulls = raw_df['velocidade'].isnull().sum()
            initial_null_percentage = (initial_nulls / total_records) * 100 if total_records > 0 else 0
            st.metric(f"Dados Ausentes Inicialmente ({route})", f"{initial_null_percentage:.1f}%")

            # Obter o ID da rota (assumindo que h√° apenas um ID por nome no per√≠odo selecionado)
            try:
                 route_id = raw_df['route_id'].iloc[0]
            except IndexError:
                 st.error(f"N√£o foi poss√≠vel obter o ID da rota para '{route}'. Dados insuficientes.")
                 logging.error(f"N√£o foi poss√≠vel obter ID da rota para '{route}'. DataFrame vazio ou sem route_id.")
                 routes_info[route] = {'data': pd.DataFrame(), 'id': None}
                 continue

            # Limpar e processar os dados
            processed_df = clean_data(raw_df)

            if processed_df.empty:
                 # Mensagem de warning j√° exibida dentro de clean_data se todos os valores forem nulos
                 routes_info[route] = {'data': pd.DataFrame(), 'id': None}
                 continue


            routes_info[route] = {
                'data': processed_df,
                'id': route_id
            }
            processed_dfs[route] = processed_df # Armazena para compara√ß√£o
        st.toast(f"Dados para {route} carregados e processados ({len(processed_df)} registros).", icon="‚úÖ") # Feedback com toast


    # --- Se√ß√£o de Visualiza√ß√£o ---

    # Se n√£o houver dados carregados para nenhuma rota, parar por aqui
    if not routes_info or all(info['data'].empty for info in routes_info.values()):
         st.info("Selecione as rotas e um per√≠odo com dados dispon√≠veis no painel lateral para continuar.")
         return # Sai da fun√ß√£o main se n√£o houver dados


    st.header("üó∫Ô∏è Visualiza√ß√£o Geogr√°fica")
    # O mapa √© exibido por rota dentro do loop de processamento
    for route in routes_to_process:
         # Verifica se a rota foi carregada com sucesso e tem dados
         if route in routes_info and not routes_info[route]['data'].empty:
             route_id = routes_info[route]['id']
             # O expander deve ser dentro do loop para que cada rota tenha seu mapa
             with st.expander(f"Mapa da Rota: {route}", expanded=True):
                  # Obter coordenadas da rota (cached)
                  route_coords = get_route_coordinates(route_id)

                  if not route_coords.empty:
                      # Calcular bounds para centralizar o mapa
                      min_lat, max_lat = route_coords['latitude'].min(), route_coords['latitude'].max()
                      min_lon, max_lon = route_coords['longitude'].min(), route_coords['longitude'].max()

                      # Adicionar um pequeno buffer
                      lat_buffer = (max_lat - min_lat) * 0.05
                      lon_buffer = (max_lon - min_lon) * 0.05

                      center_lat = (max_lat + min_lat) / 2
                      center_lon = (max_lon + min_lon) / 2

                      # Determinar um zoom inicial razo√°vel baseado nos bounds (heur√≠stica simples)
                      # Calcula a extens√£o longitudinal e ajusta o zoom
                      lon_extent = max_lon - min_lon
                      lat_extent = max_lat - min_lat
                      # F√≥rmula de zoom aproximada (ajuste conforme necess√°rio)
                      if lon_extent > 0 and lat_extent > 0:
                         zoom_lon = 360 / lon_extent
                         zoom_lat = 180 / lat_extent
                         zoom = min(zoom_lon, zoom_lat) * 0.5 # Ajuste o fator (0.5)
                         zoom = min(max(zoom, 10), 15) # Limita o zoom entre 10 e 15
                      else:
                         zoom = 12 # Zoom padr√£o se a rota for muito pequena ou um ponto

                      fig = go.Figure(go.Scattermapbox(
                          mode="lines+markers",
                          lon=route_coords['longitude'],
                          lat=route_coords['latitude'],
                          marker={'size': 8, 'color': ACCENT_COLOR},
                          line=dict(width=4, color=PRIMARY_COLOR),
                          hovertext=[f"Ponto {i+1}" for i in range(len(route_coords))],
                          hoverinfo="text+lat+lon" # Mostra texto customizado + lat/lon no tooltip
                      ))

                      fig.update_layout(
                          mapbox={
                              'style': "carto-darkmatter", # Estilo de mapa que combina com o tema escuro
                              'center': {'lat': center_lat, 'lon': center_lon},
                              'zoom': zoom,
                              # bounds podem ser usados para focar na √°rea
                              'bounds': {'west': min_lon - lon_buffer, 'east': max_lon + lon_buffer,
                                         'south': min_lat - lat_buffer, 'north': max_lat + lat_buffer}
                          },
                          margin={"r":0,"t":0,"l":0,"b":0},
                          height=500, # Altura do mapa
                          plot_bgcolor=SECONDARY_BACKGROUND_COLOR, # Fundo do plot
                          paper_bgcolor=SECONDARY_BACKGROUND_COLOR, # Fundo do papel (figura)
                          font=dict(color=TEXT_COLOR), # Cor da fonte global do gr√°fico
                          title=f"Mapa da Rota: {route}" # Adiciona t√≠tulo ao mapa
                      )
                      st.plotly_chart(fig, use_container_width=True)
                  else:
                      st.warning(f"Nenhuma coordenada geogr√°fica encontrada para a rota '{route}'. N√£o √© poss√≠vel exibir o mapa.")
         elif route in routes_info and 'error' in routes_info[route]:
              st.warning(f"Mapa n√£o dispon√≠vel para '{route}' devido a erro no carregamento de dados.")
         else:
             # Isso pode acontecer se compare_enabled for True mas a segunda rota n√£o puder ser carregada
             st.info(f"Dados insuficientes para exibir o mapa da rota '{route}'.")

    st.header("üìà An√°lise de Momento: Hist√≥rico vs Atual")
    
    # Carregar metadados das rotas
    route_metadata = get_route_metadata()
    if not route_metadata.empty:
        analysis_df = analyze_current_vs_historical(route_metadata)
        
        with st.expander("üîç Principais Observa√ß√µes", expanded=True):
            st.markdown("""
            **Rela√ß√£o Tempo vs Velocidade:**
            - Quando avg_time > historic_time: Redu√ß√£o de velocidade (congestionamento)
            - Quando avg_time < historic_time: Melhoria no fluxo
            """)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Rotas Cr√≠ticas", 
                         len(analysis_df[analysis_df['status'] == 'Cr√≠tico']))
            with col2:
                avg_delay = analysis_df['var_time'].mean()
                st.metric("Atraso M√©dio", f"{avg_delay:.1f}%")
        
        with st.expander("üö¶ Top 5 Rotas com Maiores Discrep√¢ncias"):
            top_criticas = analysis_df[analysis_df['status'] == 'Cr√≠tico'].head(5)
            if not top_criticas.empty:
                for idx, row in top_criticas.iterrows():
                    st.markdown(f"""
                    **{row['name']}**
                    - üî¥ Tempo Atual: {row['avg_time']}s (Hist√≥rico: {row['historic_time']}s)
                    - üöó Velocidade Atual: {row['avg_speed']}km/h (Hist√≥rico: {row['historic_speed']}km/h)
                    - üìà Varia√ß√£o: +{row['var_time']:.1f}% tempo | {row['var_speed']:.1f}% velocidade
                    """)
            else:
                st.info("Nenhuma rota cr√≠tica identificada")
        
        with st.expander("üìä An√°lise Detalhada por Categoria"):
            st.dataframe(
                analysis_df[['name', 'status', 'avg_time', 'historic_time', 
                           'avg_speed', 'historic_speed', 'var_time', 'var_speed']],
                column_config={
                    "name": "Rota",
                    "status": st.column_config.SelectboxColumn(
                        "Status",
                        options=["Normal", "Aten√ß√£o", "Cr√≠tico"]
                    ),
                    "avg_time": "Tempo Atual (s)",
                    "historic_time": "Tempo Hist√≥rico (s)",
                    "avg_speed": "Velocidade Atual (km/h)",
                    "historic_speed": "Velocidade Hist√≥rica (km/h)",
                    "var_time": st.column_config.ProgressColumn(
                        "Varia√ß√£o Tempo",
                        format="+%.1f%%",
                        min_value=-100,
                        max_value=300
                    ),
                    "var_speed": st.column_config.ProgressColumn(
                        "Varia√ß√£o Velocidade",
                        format="%.1f%%",
                        min_value=-100,
                        max_value=100
                    )
                },
                hide_index=True,
                use_container_width=True
            )
    else:
        st.warning("N√£o foi poss√≠vel carregar metadados das rotas")


    st.header("üìä Visualiza√ß√£o de Dados Hist√≥ricos")

    # --- Compara√ß√£o Visual de Dados Hist√≥ricos (Gr√°fico de Linha Plotly) ---
    if len(processed_dfs) > 0:
         st.subheader("Compara√ß√£o de Velocidade Hist√≥rica ao Longo do Tempo")
         fig_historical_comparison = go.Figure()

         colors = [PRIMARY_COLOR, ACCENT_COLOR] # Cores para as rotas

         for i, (r_name, r_df) in enumerate(processed_dfs.items()):
              if not r_df.empty:
                   fig_historical_comparison.add_trace(go.Scatter(
                       x=r_df['data'],
                       y=r_df['velocidade'],
                       mode='lines',
                       name=f'Hist√≥rico: {r_name}',
                       line=dict(color=colors[i % len(colors)], width=2) # Usa cores distintas
                   ))
              else:
                   st.info(f"Dados insuficientes para incluir '{r_name}' no gr√°fico de compara√ß√£o hist√≥rica.")


         if len(fig_historical_comparison.data) > 0: # Exibe apenas se houver pelo menos uma rota
              fig_historical_comparison.update_layout(
                  title='Velocidade Hist√≥rica ao Longo do Tempo',
                  xaxis_title="Data/Hora",
                  yaxis_title="Velocidade (km/h)",
                  hovermode='x unified',
                  plot_bgcolor=SECONDARY_BACKGROUND_COLOR,
                  paper_bgcolor=SECONDARY_BACKGROUND_COLOR,
                  font=dict(color=TEXT_COLOR),
                  title_font_color=TEXT_COLOR,
                  xaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                  yaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                  legend=dict(font=dict(color=TEXT_COLOR))
              )
              st.plotly_chart(fig_historical_comparison, use_container_width=True)
         elif compare_enabled:
              st.info("Dados insuficientes para realizar a compara√ß√£o hist√≥rica entre as rotas selecionadas.")


    # --- Se√ß√£o de An√°lise Preditiva ---
    st.header("üìà An√°lise Preditiva")
    for route in routes_to_process:
        # Verifica se a rota foi carregada com sucesso e tem dados processados
        if route in routes_info and not routes_info[route]['data'].empty:
            processed_df = routes_info[route]['data']
            route_id = routes_info[route]['id']

            # Expander para cada rota
            with st.expander(f"An√°lise para {route}", expanded=True):

                st.subheader("üß† Insights Autom√°ticos")
                st.markdown(gerar_insights(processed_df))

                st.subheader("üìâ Decomposi√ß√£o Temporal")
                # Passa o df processado que clean_data retornou
                # Esta fun√ß√£o usa Matplotlib, a cor do tema √© configurada DENTRO dela.
                seasonal_decomposition_plot(processed_df)


                st.subheader("üî• Heatmap Hor√°rio por Dia da Semana")
                if not processed_df.empty:
                    pivot_table = processed_df.pivot_table(
                        index='day_of_week',
                        columns='hour',
                        values='velocidade',
                        aggfunc='mean'
                    )

                    # Reordenar dias da semana (em portugu√™s)
                    dias_ordenados_eng = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                    dias_pt = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']
                    dia_mapping = dict(zip(dias_ordenados_eng, dias_pt))

                    # Reindexar a tabela pivotada para garantir a ordem dos dias
                    pivot_table = pivot_table.reindex(dias_ordenados_eng)
                    # Renomear o √≠ndice para portugu√™s
                    pivot_table.index = pivot_table.index.map(dia_mapping)


                    # --- Usar Matplotlib/Seaborn Heatmap ---
                    # Criar uma figura e eixos Matplotlib
                    fig_mpl, ax_mpl = plt.subplots(figsize=(12, 8)) # Tamanho da figura

                    # Gerar o heatmap usando Seaborn
                    sns.heatmap(
                        pivot_table,
                        annot=True,      # Mostrar os valores nas c√©lulas
                        fmt=".0f",       # Formatar os valores para 0 casas decimais (inteiro) <--- Corrigido para 0 casas decimais
                        cmap="viridis",  # Mapa de cores (similar ao Viridis do Plotly)
                        linewidths=.5,   # Adicionar linhas entre as c√©lulas para clareza
                        ax=ax_mpl        # Desenhar no eixo Matplotlib criado
                         # annot_kws={"color": TEXT_COLOR} # Opcional: cor da fonte da anota√ß√£o (pode prejudicar leitura)
                    )

                    # Configurar t√≠tulos e labels dos eixos para o tema escuro
                    ax_mpl.set_title('Velocidade M√©dia por Dia da Semana e Hora', color=TEXT_COLOR)
                    ax_mpl.set_xlabel('Hora do Dia', color=TEXT_COLOR)
                    ax_mpl.set_ylabel('Dia da Semana', color=TEXT_COLOR)

                    # Configurar cor dos ticks dos eixos e fundo do plot
                    ax_mpl.tick_params(axis='x', colors=TEXT_COLOR)
                    ax_mpl.tick_params(axis='y', colors=TEXT_COLOR)
                    ax_mpl.set_facecolor(SECONDARY_BACKGROUND_COLOR) # Fundo da √°rea do plot

                    # Configurar cor de fundo da figura inteira
                    fig_mpl.patch.set_facecolor(SECONDARY_BACKGROUND_COLOR) # Fundo da figura

                    # Configurar a cor da barra de cor (colorbar)
                    cbar = ax_mpl.collections[0].colorbar # Obter o objeto colorbar
                    if cbar:
                         cbar.ax.tick_params(colors=TEXT_COLOR) # Cor dos ticks
                         cbar.set_label('Velocidade M√©dia (km/h)', color=TEXT_COLOR) # Cor do label

                    # Exibir a figura Matplotlib no Streamlit
                    st.pyplot(fig_mpl)
                    plt.close(fig_mpl) # Fechar a figura para liberar mem√≥ria

                else:
                    st.info("Dados insuficientes para gerar o Heatmap.")


                st.subheader("üîÆ Previs√£o de Velocidade (ARIMA)")

                # Bot√£o para rodar a previs√£o (usa forecast_steps e arima_m_period definidos na sidebar)
                if st.button(f"Gerar Previs√£o para {route}", key=f"generate_forecast_{route}"):
                     forecast_df = pd.DataFrame() # Initialize DataFrame

                     # --- Try/Except para a Gera√ß√£o da Previs√£o ARIMA ---
                     try:
                         st.info(f"Iniciando gera√ß√£o da previs√£o ARIMA para {route} com per√≠odo sazonal m={arima_m_period} e {forecast_steps} passos futuros...")
                         # Chamada da fun√ß√£o de previs√£o ARIMA (agora com ex√≥genas e m_period)
                         forecast_df = create_arima_forecast(processed_df, route_id, steps=forecast_steps, m_period=arima_m_period)

                         if not forecast_df.empty:
                             st.success(f"Previs√£o gerada para os pr√≥ximos {forecast_steps * 3} minutos.")
                             st.toast("Previs√£o gerada!", icon="‚úÖ") # Feedback com toast


                             # --- Try/Except para Plotar o Gr√°fico de Previs√£o ---
                             try:
                                 st.info("Gerando gr√°fico de previs√£o...")
                                 fig_forecast = go.Figure()

                                 # Adiciona os dados hist√≥ricos
                                 fig_forecast.add_trace(go.Scatter(
                                     x=processed_df['data'],
                                     y=processed_df['velocidade'],
                                     mode='lines',
                                     name=f'Hist√≥rico: {route}', # Nome da rota no hist√≥rico
                                     line=dict(color=TEXT_COLOR, width=2) # Cor para o hist√≥rico
                                 ))

                                 # Adiciona a previs√£o
                                 fig_forecast.add_trace(go.Scatter(
                                     x=forecast_df['ds'],
                                     y=forecast_df['yhat'],
                                     mode='lines',
                                     name=f'Previs√£o: {route}', # Nome da rota na previs√£o
                                     line=dict(color=PRIMARY_COLOR, width=3) # Cor prim√°ria para a previs√£o
                                 ))

                                 # Adiciona o intervalo de confian√ßa
                                 fig_forecast.add_trace(go.Scatter(
                                     x=pd.concat([forecast_df['ds'], forecast_df['ds'][::-1]]), # Dates para o pol√≠gono (ida e volta)
                                     y=pd.concat([forecast_df['yhat_upper'], forecast_df['yhat_lower'][::-1]]), # Limites (superior e inferior invertido)
                                     fill='toself', # Preenche a √°rea entre as duas linhas
                                     fillcolor='rgba(0, 175, 255, 0.2)', # Cor semi-transparente (similar ao PRIMARY_COLOR)
                                     line=dict(color='rgba(255,255,255,0)'), # Linha invis√≠vel
                                     name=f'Intervalo de Confian√ßa 95% ({route})'
                                 ))

                                 # Configura o layout do gr√°fico de previs√£o
                                 fig_forecast.update_layout(
                                     title=f'Previs√£o de Velocidade para {route}',
                                     xaxis_title="Data/Hora",
                                     yaxis_title="Velocidade (km/h)",
                                     hovermode='x unified', # Agrupa tooltips por eixo X
                                     plot_bgcolor=SECONDARY_BACKGROUND_COLOR,
                                     paper_bgcolor=SECONDARY_BACKGROUND_COLOR,
                                     font=dict(color=TEXT_COLOR),
                                     title_font_color=TEXT_COLOR,
                                     xaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                                     yaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                                     legend=dict(font=dict(color=TEXT_COLOR))
                                 )

                                 st.plotly_chart(fig_forecast, use_container_width=True)
                                 st.success("Gr√°fico de previs√£o gerado.")


                             except Exception as e:
                                 logging.exception("Erro ao gerar ou exibir o gr√°fico de previs√£o:") # Log detalhado
                                 st.error(f"Erro ao gerar ou exibir o gr√°fico de previs√£o: {e}")
                                 st.info("Verifique se h√° dados suficientes na previs√£o gerada ou se h√° problemas na configura√ß√£o do gr√°fico Plotly.")

                             # --- Try/Except para Salvar no Banco de Dados ---
                             # O bot√£o de salvar s√≥ aparece AP√ìS a previs√£o ser gerada e plotada
                             if st.button(f"Salvar Previs√£o no Banco de Dados para {route}", key=f"save_forecast_{route}"):
                                  save_forecast_to_db(forecast_df)


                         else:
                             st.warning("Previs√£o n√£o gerada ou DataFrame de previs√£o vazio. N√£o √© poss√≠vel exibir o gr√°fico ou salvar.")
                             st.toast("Previs√£o falhou!", icon="‚ùå") # Feedback com toast

                     except Exception as e:
                         logging.exception("Erro fatal durante a gera√ß√£o da previs√£o ARIMA:") # Log detalhado
                         st.error(f"Erro fatal durante a gera√ß√£o da previs√£o ARIMA: {e}")
                         st.info("Verifique os dados de entrada, a quantidade de dados, ou a configura√ß√£o do modelo ARIMA.")
                         st.toast("Previs√£o falhou!", icon="‚ùå") # Feedback com toast


                # Mensagem inicial antes de gerar a previs√£o
                elif f"generate_forecast_{route}" not in st.session_state:
                    st.info("Configure o per√≠odo sazonal e os passos futuros na sidebar e clique em 'Gerar Previs√£o'.")


        # Adiciona uma linha separadora entre as an√°lises de rotas se houver mais de uma
        if len(routes_to_process) > 1 and routes_to_process.index(route) < len(routes_to_process) - 1:
            st.markdown("---") # Linha horizontal

    # Mensagem final caso nenhuma rota tenha dados
    if not routes_info or all(info['data'].empty for info in routes_info.values()):
         st.info("Nenhuma an√°lise exibida. Selecione rotas com dados dispon√≠veis.")


# --- Executa o aplicativo Streamlit ---
if __name__ == "__main__":
    main()