import streamlit as st
import logging # Importar a biblioteca de logging

# ConfiguraÃ§Ã£o da pÃ¡gina DEVE SER A PRIMEIRA CHAMADA
st.set_page_config(
    page_title="AnÃ¡lise de Rotas Inteligente",
    layout="wide",
    page_icon="ðŸ“Š"
)

# Restante das importaÃ§Ãµes
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
# Importar matplotlib e seaborn para o heatmap e decomposiÃ§Ã£o
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
import plotly.express as px # Mantido para caso precise em outros lugares (mapa usa go, previsÃ£o usa go)
import plotly.graph_objects as go
from io import BytesIO
import mysql.connector
import pytz
from pmdarima import auto_arima
from sklearn.metrics import mean_absolute_error
import datetime # Importar datetime para manipular dates
import holidays # Importar a biblioteca holidays para feriados


# ConfiguraÃ§Ãµes de compatibilidade do numpy (manter se for necessÃ¡rio no seu ambiente)
# Isso pode nÃ£o ser necessÃ¡rio dependendo da versÃ£o do numpy, mas Ã© seguro manter
if np.__version__.startswith('2.'):
    np.float_ = np.float64
    np.int_ = np.int_
    np.bool_ = np.bool_

# Tema personalizado MELHORADO E COERENTE COM FUNDO ESCURO
# Definindo as cores em variÃ¡veis para fÃ¡cil referÃªncia
PRIMARY_COLOR = "#00AFFF"         # Azul mais claro e vibrante
BACKGROUND_COLOR = "#1E1E1E"      # Cinza escuro para o fundo principal
SECONDARY_BACKGROUND_COLOR = "#2D2D2D" # Cinza um pouco mais claro para sidebar/elementos
ACCENT_COLOR = "#FF4B4B"          # Vermelho para destaque/alertas
TEXT_COLOR = "#FFFFFF"            # Branco
HEADER_FONT = 'Segoe UI', 'sans-serif' # Fonte

custom_theme = f"""
<style>
:root {{
Â  Â  --primary-color: {PRIMARY_COLOR};
Â  Â  --background-color: {BACKGROUND_COLOR};
Â  Â  --secondary-background-color: {SECONDARY_BACKGROUND_COLOR};
Â  Â  --accent-color: {ACCENT_COLOR};
Â  Â  --text-color: {TEXT_COLOR};
Â  Â  --header-font: {', '.join(HEADER_FONT)};
Â  Â  /* --text-color-sidebar: {TEXT_COLOR_SIDEBAR}; <-- Linha removida ou comentada */
}}

html, body, [class*="css"] {{
Â  Â  font-family: var(--header-font);
Â  Â  color: var(--text-color);
Â  Â  background-color: var(--background-color);
}}

h1, h2, h3, h4, h5, h6 {{
Â  Â  color: var(--primary-color);
Â  Â  font-weight: 600;
}}

/* Ajustar a cor do texto dentro de expanders para melhor contraste */
.stExpander {{
Â  Â  background-color: var(--secondary-background-color);
Â  Â  padding: 10px; /* Adiciona um pouco de padding */
Â  Â  border-radius: 8px;
Â  Â  margin-bottom: 15px; /* EspaÃ§o entre expanders */
}}

.stExpander > div > div > p {{
Â  Â  Â color: var(--text-color); /* Garante que o texto dentro do expander seja visÃ­vel */
}}
/* Ajustar cor do header do expander */
.stExpander > div > div > .st-emotion-cache-p5msec {{
Â  Â  color: var(--text-color); /* Garante que o tÃ­tulo do expander seja visÃ­vel */
}}


.stApp {{
Â  Â  background-color: var(--background-color);
Â  Â  color: var(--text-color); /* Garante que o texto geral do app use a cor definida */
}}

/* --- Ajustes especÃ­ficos para a sidebar (MELHORADOS) --- */
.stSidebar {{
Â  Â  background-color: var(--secondary-background-color) !important; /* Garantir fundo escuro */
Â  Â  color: var(--text-color); /* Cor do texto geral na sidebar (herdado) */
}}

.stSidebar .stMarkdown {{
Â  Â  Â color: var(--text-color); /* Garante que o markdown na sidebar use a cor definida */
}}

/* Melhorar aparÃªncia de elementos de input e labels dentro da sidebar */
.stSidebar label {{ /* Alvo: todos os labels dentro da sidebar (checkbox, selectbox, slider, date input, etc.) */
Â  Â  color: var(--text-color);
}}

.stSidebar div[data-baseweb="select"] > div {{ /* Alvo: texto interno de selectbox */
Â  Â  Â background-color: var(--secondary-background-color);
Â  Â  Â color: var(--text-color);
Â  Â  Â border: 1px solid #555;
}}

.stSidebar input[type="text"], /* Alvo: inputs de texto */
.stSidebar input[type="date"], /* Alvo: inputs de data */
.stSidebar input[type="number"] /* Alvo: inputs numÃ©ricos */
{{
Â  Â  color: var(--text-color);
Â  Â  background-color: var(--secondary-background-color);
Â  Â  border: 1px solid #555;
Â  Â  border-radius: 4px;
Â  Â  padding: 5px;
}}

.stSidebar .stSlider [data-baseweb="slider"] > div {{ /* Alvo: barra preenchida do slider */
Â  Â  background-color: var(--primary-color);
}}

.stSidebar .stRadio > label {{ /* Alvo: labels de radio buttons */
Â  Â  Â color: var(--text-color);
}}

/* Garantir que o texto dos botÃµes na sidebar seja visÃ­vel */
/* Adicione !important se a heranÃ§a estiver causando problemas */
.stSidebar button {{
Â  Â  color: white !important; /* ForÃ§a a cor do texto do botÃ£o para branco */
}}

/* Adicionar regras para outros elementos comuns na sidebar se necessÃ¡rio */
/* st.text_area, st.time_input, etc. */

/* --- Fim ajustes sidebar --- */


.stButton>button {{
Â  Â  background-color: var(--primary-color);
Â  Â  color: white;
Â  Â  border-radius: 8åŽmpx;
Â  Â  border: none; /* Remover borda padrÃ£o */
Â  Â  padding: 10px 20px; /* Padding para melhor aparÃªncia */
Â  Â  cursor: pointer;
}}

.stButton>button:hover {{
Â  Â  background-color: #0099E6; /* Cor um pouco mais escura no hover */
}}

.stCheckbox>label {{
Â  Â  color: var(--text-color);
}}

.stSelectbox>label {{
Â  Â  color: var(--text-color);
}}
/* Melhorar aparÃªncia do selectbox - Regra global */
.stSelectbox > div[data-baseweb="select"] > div {{
Â  Â  Â background-color: var(--secondary-background-color);
Â  Â  Â color: var(--text-color);
Â  Â  Â border: 1px solid #555;
}}


/* Melhorar aparÃªncia do date input - Regra global */
.stDateInput > label {{
Â  Â  color: var(--text-color);
}}

.stDateInput input {{
Â  Â  color: var(--text-color);
Â  Â  background-color: var(--secondary-background-color);
Â  Â  border: 1px solid #555; /* Borda sutil */
Â  Â  border-radius: 4px;
Â  Â  padding: 5px;
}}

/* Melhorar aparÃªncia do slider - Regra global */
.stSlider > label {{
Â  Â  color: var(--text-color);
}}

.stSlider [data-baseweb="slider"] > div {{
Â  Â  background-color: var(--primary-color); /* Cor da barra preenchida */
}}


.stSpinner > div > div {{
Â  Â  color: var(--primary-color); /* Cor do spinner */
}}

/* Estilo para mensagens de aviso */
.stAlert > div {{
Â  Â  background-color: rgba(255, 255, 0, 0.1); /* Amarelo semi-transparente */
Â  Â  color: {TEXT_COLOR};
Â  Â  border-color: yellow;
}}

/* Estilo para mensagens de erro */
.stAlert[kind="error"] > div {{
Â  Â  background-color: rgba(255, 0, 0, 0.1); /* Vermelho semi-transparente */
Â  Â  color: {TEXT_COLOR};
Â  Â  border-color: red;
}}

/* Estilo para mensagens de sucesso */
.stAlert[kind="success"] > div {{
Â  Â  background-color: rgba(0, 255, 0, 0.1); /* Verde semi-transparente */
Â  Â  color: {TEXT_COLOR};
Â  Â  border-color: green;
}}

/* Adiciona hover effect nos botÃµes */
.stButton button:hover {{
Â  Â  opacity: 0.9;
Â  Â  transform: scale(1.02);
Â  Â  transition: all 0.2s ease-in-out;
}}
/* Ajustar o padding da pÃ¡gina principal */
.stApp > header, .stApp > div {{
Â  Â  padding-top: 1rem;
Â  Â  padding-bottom: 1rem;
}}

</style>
"""
st.markdown(custom_theme, unsafe_allow_html=True)


# --- FunÃ§Ãµes de Banco de Dados e Carga ---

# Use st.secrets para credenciais de banco de dados
# Para configurar: crie um arquivo .streamlit/secrets.toml na raiz do seu projeto
# Exemplo:
# [mysql]
# host = "185.213.81.52"
# user = "u335174317_wazeportal"
# password = "@Ndre2025." # Mude isso para sua senha real ou use secrets
# database = "u335174317_wazeportal"

@st.cache_resource # Usar cache_resource para conexÃµes de DB
def get_db_connection():
    """
    Estabelece e retorna uma conexÃ£o com o banco de dados MySQL.
    A conexÃ£o Ã© cacheada pelo Streamlit.
    """
    try:
        # ConfiguraÃ§Ã£o de pooling ou outras otimizaÃ§Ãµes podem ser adicionadas aqui
        conn = mysql.connector.connect(
            host=st.secrets["mysql"]["host"],
            user=st.secrets["mysql"]["user"],
            password=st.secrets["mysql"]["password"],
            database=st.secrets["mysql"]["database"]
        )
        return conn
    except Exception as e:
        logging.exception("Erro ao conectar ao banco de dados:") # Log detalhado
        st.error(f"Erro ao conectar ao banco de dados: {e}")
        st.stop() # Parar a execuÃ§Ã£o se nÃ£o conseguir conectar

@st.cache_data # Usar cache_data para os dados histÃ³ricos, dependendo dos parÃ¢metros
def get_data(start_date=None, end_date=None, route_name=None):
    """
    Busca dados histÃ³ricos de velocidade do banco de dados para uma rota e perÃ­odo especÃ­ficos.

    Args:
        start_date (str, optional): Data de inÃ­cio no formato YYYY-MM-DD. Defaults to None.
        end_date (str, optional): Data de fim no formato YYYY-MM-DD. Defaults to None.
        route_name (str, optional): Nome da rota. Defaults to None.

    Returns:
        tuple[pd.DataFrame, str | None]: DataFrame com os dados e mensagem de erro (se houver).
    """
    mydb = None
    mycursor = None
    try:
        mydb = get_db_connection()
        mycursor = mydb.cursor()

        query = """
            SELECT hr.route_id, r.name AS route_name, hr.data, hr.velocidade
            FROM historic_routes hr
            JOIN routes r ON hr.route_id = r.id
        """
        conditions = []
        params = []

        if route_name:
            conditions.append("r.name = %s")
            params.append(route_name)
        if start_date:
            conditions.append("hr.data >= %s")
            params.append(start_date)
        if end_date:
             # Para incluir o Ãºltimo dia completo, filtrar por < (data final + 1 dia)
            end_datetime = pd.to_datetime(end_date) + pd.Timedelta(days=1)
            end_date_plus_one_day_str = end_datetime.strftime('%Y-%m-%d')

            conditions.append("hr.data < %s") # Usar o operador MENOR QUE (<)
            params.append(end_date_plus_one_day_str) # Usar a data final + 1 dia

        if conditions:
            query += " WHERE " + " AND ".join(conditions)

        query += " ORDER BY hr.data ASC"

        mycursor.execute(query, params)
        results = mycursor.fetchall()
        col_names = [desc[0] for desc in mycursor.description]
        df = pd.DataFrame(results, columns=col_names)

        # Convertendo 'data' para datetime e 'velocidade' para numÃ©rico
        df['data'] = pd.to_datetime(df['data']).dt.tz_localize(None) # Remover timezone se presente
        df['velocidade'] = pd.to_numeric(df['velocidade'], errors='coerce')

        return df, None
    except Exception as e:
        logging.exception(f"Erro ao obter dados para rota {route_name}:") # Log detalhado
        return pd.DataFrame(), str(e) # Retorna DataFrame vazio e erro
    finally:
        if mycursor:
            mycursor.close()
        # NÃ£o feche a conexÃ£o 'mydb' aqui, pois ela Ã© gerenciada por st.cache_resource

@st.cache_data # Usar cache_data para dados estÃ¡ticos como nomes de rotas
def get_all_route_names():
    """
    Busca todos os nomes de rotas distintos no banco de dados.
    A lista de nomes Ã© cacheada pelo Streamlit.

    Returns:
        list[str]: Lista de nomes de rotas.
    """
    mydb = None
    mycursor = None
    try:
        mydb = get_db_connection()
        mycursor = mydb.cursor()
        query = "SELECT DISTINCT name FROM routes"
        mycursor.execute(query)
        results = mycursor.fetchall()
        return [row[0] for row in results]
    except Exception as e:
        logging.exception("Erro ao obter nomes das rotas:") # Log detalhado
        st.error(f"Erro ao obter nomes das rotas: {e}")
        return []
    finally:
        if mycursor:
            mycursor.close()
        # NÃ£o feche a conexÃ£o 'mydb' aqui, pois ela Ã© gerenciada por st.cache_resource

@st.cache_data # Usar cache_data para coordenadas de rota
def get_route_coordinates(route_id):
    """
    Busca as coordenadas geogrÃ¡ficas (linha) para uma rota especÃ­fica.
    As coordenadas sÃ£o cacheadas pelo Streamlit.

    Args:
        route_id (int): ID da rota.

    Returns:
        pd.DataFrame: DataFrame com colunas 'longitude' e 'latitude'.
    """
    mydb = None
    mycursor = None
    try:
        mydb = get_db_connection()
        mycursor = mydb.cursor()
        query = "SELECT x, y FROM route_lines WHERE route_id = %s ORDER BY id"
        mycursor.execute(query, (route_id,))
        results = mycursor.fetchall()
        df = pd.DataFrame(results, columns=['longitude', 'latitude'])
        return df
    except Exception as e:
        logging.exception(f"Erro ao obter coordenadas para route_id {route_id}:") # Log detalhado
        st.error(f"Erro ao obter coordenadas: {e}")
        return pd.DataFrame()
    finally:
        if mycursor:
            mycursor.close()
        # NÃ£o feche a conexÃ£o 'mydb' aqui, pois ela Ã© gerenciada por st.cache_resource

# --- FunÃ§Ãµes de Processamento e AnÃ¡lise ---

def clean_data(df):
    """
    Limpa, interpola e adiciona features temporais a um DataFrame de velocidade.

    Args:
        df (pd.DataFrame): DataFrame bruto com colunas 'data' e 'velocidade'.

    Returns:
        pd.DataFrame: DataFrame limpo com 'day_of_week' e 'hour' adicionados.
                      Retorna DataFrame vazio se todas as velocidades forem nulas.
    """
    if df.empty:
        return pd.DataFrame()

    df = df.copy()

    # Adicionar validaÃ§Ã£o de dados: verificar se todas as velocidades estÃ£o nulas
    if df['velocidade'].isnull().all():
        st.warning("ApÃ³s o carregamento, todas as velocidades estÃ£o nulas. Verifique os dados de origem ou o perÃ­odo selecionado.")
        return pd.DataFrame() # Retorna DataFrame vazio se todos os valores sÃ£o nulos

    # Assume que o DataFrame jÃ¡ estÃ¡ filtrado pela rota e perÃ­odo
    # e que a coluna 'data' jÃ¡ Ã© datetime sem timezone e 'velocidade' Ã© numÃ©rica
    df = df.sort_values('data')
    df['velocidade'] = (
        df['velocidade']
        .clip(upper=150) # Limita a velocidade a 150 km/h
        .interpolate(method='linear') # Interpola valores ausentes linearmente
        .ffill() # Preenche valores restantes com o Ãºltimo valor vÃ¡lido
        .bfill() # Preenche valores restantes com o prÃ³ximo valor vÃ¡lido
    )
    # Recalcular dia da semana e hora apÃ³s interpolaÃ§Ã£o/limpeza, se necessÃ¡rio
    # Usar locale para nomes dos dias em portuguÃªs
    # import locale
    # locale.setlocale(locale.LC_TIME, 'pt_BR.UTF8') # Configurar localidade (pode precisar instalar no ambiente)
    df['day_of_week'] = df['data'].dt.day_name() # Retorna em inglÃªs por padrÃ£o, mapearemos para o heatmap
    df['hour'] = df['data'].dt.hour
    return df.dropna(subset=['velocidade']) # Remove linhas onde a velocidade ainda Ã© NaN


def seasonal_decomposition_plot(df):
    """
    Realiza e plota a decomposiÃ§Ã£o sazonal de uma sÃ©rie temporal de velocidade.

    Args:
        df (pd.DataFrame): DataFrame com dados limpos e Ã­ndice de tempo.
    """
    if df.empty:
        st.info("NÃ£o hÃ¡ dados para realizar a decomposiÃ§Ã£o sazonal.")
        return

    # Garantir frequÃªncia temporal, interpolando se houver lacunas curtas
    # Usa a coluna 'data' como Ã­ndice e define a frequÃªncia como 3 minutos
    df_ts = df.set_index('data')['velocidade'].asfreq('3min')

    # Interpolar apenas se houver dados suficientes apÃ³s asfreq
    # Verifica a proporÃ§Ã£o de NaNs antes de interpolar
    if df_ts.isnull().sum() / len(df_ts) > 0.2: # Exemplo: Se mais de 20% dos dados sÃ£o NaN apÃ³s asfreq
         st.warning("Muitos dados faltantes ou espaÃ§ados para interpolaÃ§Ã£o e decomposiÃ§Ã£o sazonal confiÃ¡veis.")
         return

    df_ts = df_ts.interpolate(method='time')

    # O perÃ­odo para sazonalidade diÃ¡ria em dados de 3 em 3 minutos Ã© 480 (24 horas * 60 min / 3 min)
    period = 480 # Usando o perÃ­odo padrÃ£o

    # Precisa de pelo menos 2 ciclos completos de dados para decomposiÃ§Ã£o sazonal
    if len(df_ts.dropna()) < 2 * period:
         st.warning(f"Dados insuficientes para decomposiÃ§Ã£o sazonal com perÃ­odo de {period}. NecessÃ¡rio pelo menos {2*period} pontos de dados vÃ¡lidos.")
         return

    try:
        # model='additive' Ã© geralmente adequado para velocidade onde as variaÃ§Ãµes sÃ£o mais constantes
        decomposition = seasonal_decompose(df_ts.dropna(), model='additive', period=period)
        fig, ax = plt.subplots(4, 1, figsize=(12, 10)) # Adiciona componente de ResÃ­duo
        decomposition.observed.plot(ax=ax[0], title='Observado')
        decomposition.trend.plot(ax=ax[1], title='TendÃªncia')
        decomposition.seasonal.plot(ax=ax[2], title=f'Sazonalidade (Periodo {period})')
        decomposition.resid.plot(ax=ax[3], title='ResÃ­duo')
        plt.tight_layout()

        # Configurar cores dos eixos e tÃ­tulos para o tema escuro
        for a in ax:
            a.tick_params(axis='x', colors=TEXT_COLOR)
            a.tick_params(axis='y', colors=TEXT_COLOR)
            a.title.set_color(TEXT_COLOR)
            a.xaxis.label.set_color(TEXT_COLOR)
            a.yaxis.label.set_color(TEXT_COLOR)
            # Fundo dos subplots
            a.set_facecolor(SECONDARY_BACKGROUND_COLOR)

        # Configurar cor de fundo da figura
        fig.patch.set_facecolor(SECONDARY_BACKGROUND_COLOR)

        st.pyplot(fig)
    except Exception as e:
         logging.exception("Erro ao realizar decomposiÃ§Ã£o sazonal:") # Log detalhado
         st.warning(f"NÃ£o foi possÃ­vel realizar a decomposiÃ§Ã£o sazonal: {e}")
         st.info("Verifique se os dados tÃªm uma frequÃªncia regular ou se hÃ¡ dados suficientes.")


def create_holiday_exog(index):
    """
    Cria features exÃ³genas binÃ¡rias ('is_holiday' e 'is_pre_holiday') para um DateTimeIndex.

    Args:
        index (pd.DateTimeIndex): Ãndice de tempo para o qual gerar as features.

    Returns:
        pd.DataFrame: DataFrame com as colunas 'is_holiday' e 'is_pre_holiday'.
    """
    if index.empty:
        return pd.DataFrame(index=index)

    # Obter feriados brasileiros para os anos presentes no Ã­ndice
    br_holidays = holidays.CountryHoliday('BR', years=index.year.unique())
    exog_df = pd.DataFrame(index=index)

    # is_holiday: Verifica se a data do timestamp atual Ã© um feriado
    exog_df['is_holiday'] = index.to_series().apply(lambda date: date.date() in br_holidays).astype(int)

    # is_pre_holiday: Verifica se a data EXATAMENTE 24 horas a partir do timestamp atual Ã© um feriado,
    # E a data atual NÃƒO Ã© um feriado.
    # Isso requer que o Ã­ndice tenha uma frequÃªncia regular definida por asfreq.
    if index.freq is None:
         # Fallback para frequÃªncia irregular - verifica se o prÃ³ximo dia CALENDAR (24h) Ã© um feriado
         exog_df['is_pre_holiday'] = index.to_series().apply(
             lambda date: (date + pd.Timedelta(days=1)).date() in br_holidays and date.date() not in br_holidays
         ).astype(int)
    else:
        # Usa a frequÃªncia para calcular um offset exato de 24 horas
        one_day_offset = pd.Timedelta(days=1)
        # Cria uma sÃ©rie de dates exatamente 24 horas no futuro com base na frequÃªncia do Ã­ndice
        dates_in_24h = index + one_day_offset
        # Verifica se a data 24 hours later Ã© um feriado
        is_next_day_holiday = dates_in_24h.to_series().apply(lambda date: date.date() in br_holidays).astype(int)
        # Uma data Ã© vÃ©spera de feriado se a data 24h later Ã© feriado E a data atual NÃƒO Ã© feriado
        exog_df['is_pre_holiday'] = is_next_day_holiday & (exog_df['is_holiday'] == 0)

    return exog_df


# FunÃ§Ã£o de previsÃ£o ARIMA (revisada para usar intervalos de confianÃ§a e tratamento de dados E EXOG)
# NÃ£o cacheamos previsÃµes pois elas dependem de dados recentes e podem ser acionadas pelo usuÃ¡rio
# @st.cache_data # NÃ£o use cache_data para previsÃµes se elas devem ser geradas sob demanda
def create_arima_forecast(df, route_id, steps=10, m_period=480):
    """
    Cria e executa um modelo de previsÃ£o ARIMA sazonal com variÃ¡veis exÃ³genas (feriados/vÃ©speras).

    Args:
        df (pd.DataFrame): DataFrame com dados histÃ³ricos de velocidade limpos.
        route_id (int): ID da rota.
        steps (int, optional): NÃºmero de passos futuros para prever. Defaults to 10.
        m_period (int, optional): PerÃ­odo sazonal para o auto_arima. Defaults to 480 (diÃ¡rio @ 3min).

    Returns:
        pd.DataFrame: DataFrame com a previsÃ£o (datas, yhat, limites de confianÃ§a) ou DataFrame vazio em caso de falha.
    """
    if df.empty:
        # Mensagem jÃ¡ exibida na chamada
        return pd.DataFrame()

    # Preparar dados para auto_arima (jÃ¡ vem limpo)
    # Garantir frequÃªncia temporal, interpolando se houver lacunas curtas
    arima_data_full = df.set_index('data')['velocidade'].asfreq('3min').dropna()

    # Criar features exÃ³genas (feriados e vÃ©speras) para o perÃ­odo dos dados histÃ³ricos
    exog_data_full = create_holiday_exog(arima_data_full.index)

    # Alinhar dados da sÃ©rie temporal (y) e dados exÃ³genos (X) usando um join interno
    # Isso garante que temos 'y' e 'X' para os mesmos timestamps
    combined_df = arima_data_full.to_frame(name='y').join(exog_data_full, how='inner').dropna()
    arima_data = combined_df['y']
    exog_data = combined_df[['is_holiday', 'is_pre_holiday']]


    # Precisa de dados suficientes para o modelo sazonal ARIMA
    # Um mÃ­nimo de 2-3 ciclos sazonais Ã© recomendado
    min_data_points = 2 * m_period # MÃ­nimo 2 ciclos completos para detectar sazonalidade

    if len(arima_data) < min_data_points:
         st.warning(f"Dados insuficientes ({len(arima_data)} pontos) para treinar um modelo de previsÃ£o ARIMA sazonal robusto com perÃ­odo {m_period}. NecessÃ¡rio pelo menos {int(min_data_points)} pontos vÃ¡lidos apÃ³s alinhamento.")
         return pd.DataFrame()

    try:
        # auto_arima encontrarÃ¡ os melhores parÃ¢metros p,d,q,P,D,Q
        # Passando o perÃ­odo sazonal 'm' selecionado pelo usuÃ¡rio
        # PASSANDO DADOS EXÃ“GENOS (X=exog_data)
        with st.spinner(f"Treinando modelo ARIMA para a rota {route_id} com perÃ­odo sazonal m={m_period}..."):
             model = auto_arima(arima_data, X=exog_data, seasonal=True, m=m_period,
                                error_action='ignore', suppress_warnings=True,
                                stepwise=True, random_state=42,
                                n_fits=20) # Limitar o nÃºmero de fits para evitar tempo excessivo

        # Gerar dates futuras com base na Ãºltima data histÃ³rica e frequÃªncia
        last_date = arima_data.index.max()
        # A frequÃªncia deve ser compatÃ­vel com m=480 ou 3360 (baseado em 3min)
        freq_str = '3min' # Assumindo 3minutos como base

        future_dates = pd.date_range(start=last_date, periods=steps + 1, freq=freq_str)[1:]

        # Criar features exÃ³genas (feriados e vÃ©speras) para o PERÃODO DA PREVISÃƒO
        future_exog_data = create_holiday_exog(future_dates)
        # Garantir que o Ã­ndice dos dados exÃ³genos futuros corresponda exatamente Ã s dates futuras
        future_exog_data = future_exog_data.reindex(future_dates)


        # Realizar a previsÃ£o com intervalos de confianÃ§a
        # PASSANDO DADOS EXÃ“GENOS FUTUROS (X=future_exog_data)
        forecast, conf_int = model.predict(n_periods=steps, return_conf_int=True, X=future_exog_data)


        forecast_df = pd.DataFrame({
            'ds': future_dates,
            'yhat': forecast,
            'yhat_lower': conf_int[:, 0], # Limite inferior do intervalo de confianÃ§a
            'yhat_upper': conf_int[:, 1], # Limite superior do intervalo de confianÃ§a
            'id_route': route_id
        })

        # Garante que as previsÃµes e intervalos de confianÃ§a nÃ£o sÃ£o negativos
        forecast_df[['yhat', 'yhat_lower', 'yhat_upper']] = forecast_df[['yhat', 'yhat_lower', 'yhat_upper']].clip(lower=0)

        return forecast_df
    except Exception as e:
        logging.exception("Erro durante o treinamento ou previsÃ£o do modelo ARIMA:") # Log detalhado
        st.error(f"Erro durante o treinamento ou previsÃ£o do modelo ARIMA: {str(e)}")
        st.info("Verifique os dados de entrada, a quantidade de dados, ou a configuraÃ§Ã£o do modelo ARIMA.")
        return pd.DataFrame()


def save_forecast_to_db(forecast_df):
    """
    Salva um DataFrame de previsÃ£o no banco de dados.

    Args:
        forecast_df (pd.DataFrame): DataFrame com a previsÃ£o a ser salva.
    """
    if forecast_df.empty:
        st.warning("NÃ£o hÃ¡ previsÃ£o para salvar no banco de dados.")
        return # NÃ£o salva se o DataFrame estiver vazio

    # Ajustar nomes de colunas para corresponder Ã  tabela forecast_history
    # Assumindo que a tabela forecast_history tem colunas como 'data', 'previsao', 'limite_inferior', 'limite_superior', 'id_rota'
    forecast_df_mapped = forecast_df.rename(columns={
        'ds': 'data',
        'yhat': 'previsao',
        'yhat_lower': 'limite_inferior',
        'yhat_upper': 'limite_superior',
        'id_route': 'id_rota'
    })

    # Selecionar apenas as colunas que vocÃª quer salvar
    cols_to_save = ['data', 'previsao', 'limite_inferior', 'limite_superior', 'id_rota']
    forecast_df_mapped = forecast_df_mapped[cols_to_save]

    try:
        # st.info("Conectando ao banco de dados para salvar previsÃ£o...") # SubstituÃ­do por toast/log
        # Usando credenciais do secrets
        engine = create_engine(
            f'mysql+mysqlconnector://{st.secrets["mysql"]["user"]}:{st.secrets["mysql"]["password"]}@{st.secrets["mysql"]["host"]}/{st.secrets["mysql"]["database"]}'
        )
        # Usando o gerenciador de contexto do SQLAlchemy para garantir commit/rollback e fechar a conexÃ£o
        # if_exists='append' adiciona novas linhas. Se vocÃª precisar evitar duplicatas,
        # pode precisar de uma lÃ³gica de upsert ou verificar antes de inserir.
        with engine.begin() as connection:
             # st.info("Salvando previsÃ£o na tabela forecast_history...") # SubstituÃ­do por toast/log
             # Converte datetime para tipo compatÃ­vel com SQL, como string ou timestamp
             forecast_df_mapped['data'] = forecast_df_mapped['data'].dt.strftime('%Y-%m-%d %H:%M:%S')
             forecast_df_mapped.to_sql('forecast_history', con=connection, if_exists='append', index=False)
             st.toast("PrevisÃ£o salva no banco de dados!", icon="âœ…") # Feedback ao usuÃ¡rio com toast
    except Exception as e:
        logging.exception("Erro ao salvar previsÃ£o no banco de dados:") # Log detalhado
        st.error(f"Erro ao salvar previsÃ£o no banco de dados: {e}")


def gerar_insights(df):
    """
    Gera insights automÃ¡ticos sobre a velocidade mÃ©dia, dia mais lento, etc.

    Args:
        df (pd.DataFrame): DataFrame com dados histÃ³ricos de velocidade processados.

    Returns:
        str: String formatada com os insights.
    """
    insights = []
    if df.empty:
        return "NÃ£o hÃ¡ dados para gerar insights neste perÃ­odo."

    media_geral = df['velocidade'].mean()
    insights.append(f"ðŸ“Œ Velocidade mÃ©dia geral: **{media_geral:.2f} km/h**")

    # Encontrar o dia (data especÃ­fica) com a menor velocidade mÃ©dia dentro do perÃ­odo selecionado
    if 'data' in df.columns and not df['data'].empty:
        # Agrupar por data (apenas a parte da data)
        daily_avg = df.groupby(df['data'].dt.date)['velocidade'].mean()
        if not daily_avg.empty:
            dia_mais_lento_date = daily_avg.idxmin()
            velocidade_dia_mais_lento = daily_avg.min()
            insights.append(f"ðŸ“… Dia com a menor velocidade mÃ©dia: **{dia_mais_lento_date.strftime('%d/%m/%Y')}** ({velocidade_dia_mais_lento:.2f} km/h)")
        else:
             insights.append("NÃ£o foi possÃ­vel calcular a velocidade mÃ©dia diÃ¡ria.")
    else:
         insights.append("Coluna 'data' nÃ£o encontrada ou vazia no DataFrame para insights diÃ¡rios.")


    # Encontrar o dia da semana mais lento em mÃ©dia
    if 'day_of_week' in df.columns and not df['day_of_week'].empty:
            weekday_avg = df.groupby('day_of_week')['velocidade'].mean()
            if not weekday_avg.empty:
                # Mapeamento para portuguÃªs e ordenaÃ§Ã£o
                dias_pt_map = {
                    'Monday': 'Segunda-feira', 'Tuesday': 'TerÃ§a-feira', 'Wednesday': 'Quarta-feira',
                    'Thursday': 'Quinta-feira', 'Friday': 'Sexta-feira', 'Saturday': 'SÃ¡bado', 'Sunday': 'Domingo'
                }
                weekday_avg_pt = weekday_avg.rename(index=dias_pt_map) # <-- Esta Ã© a linha 662 corrigida
                dias_ordenados_pt = ['Segunda-feira', 'TerÃ§a-feira', 'Quarta-feira', 'Quinta-feira', 'Sexta-feira', 'SÃ¡bado', 'Domingo']
                weekday_avg_pt = weekday_avg_pt.reindex(dias_ordenados_pt)

                dia_da_semana_mais_lento = weekday_avg_pt.idxmin()
                insights.append(f"ðŸ—“ï¸ Dia da semana mais lento (em mÃ©dia): **{dia_da_semana_mais_lento}**")
            else:
                insights.append("NÃ£o foi possÃ­vel calcular a velocidade mÃ©dia por dia da semana.")
    else:
        insights.append("Coluna 'day_of_week' nÃ£o encontrada ou vazia no DataFrame para insights por dia da semana.")

    # Encontrar a hora do dia mais lenta em mÃ©dia
    if 'hour' in df.columns and not df['hour'].empty:
        hourly_avg = df.groupby('hour')['velocidade'].mean()
        if not hourly_avg.empty:
            hora_mais_lenta = hourly_avg.idxmin()
            insights.append(f"ðŸ•’ Hora do dia mais lenta (em mÃ©dia): **{hora_mais_lenta:02d}:00**")
        else:
             insights.append("NÃ£o foi possÃ­vel calcular a velocidade mÃ©dia por hora do dia.")
    else:
         insights.append("Coluna 'hour' nÃ£o encontrada ou vazia no DataFrame para insights por hora.")


    return "\n\n".join(insights)

# --- FunÃ§Ã£o Principal do Aplicativo Streamlit ---

def main():
    """
    FunÃ§Ã£o principal que configura a interface do Streamlit, carrega dados
    e exibe anÃ¡lises e previsÃµes.
    """
    # Verificar se as secrets do banco de dados estÃ£o configuradas
    if "mysql" not in st.secrets or not all(k in st.secrets["mysql"] for k in ("host", "user", "password", "database")):
        st.error("As credenciais do banco de dados nÃ£o foram configuradas corretamente no secrets.toml.")
        st.markdown("Por favor, crie ou atualize o arquivo `.streamlit/secrets.toml` na raiz do seu projeto com as informaÃ§Ãµes de conexÃ£o do MySQL.")
        logging.error("Secrets do banco de dados nÃ£o configuradas.") # Log detalhado
        st.stop() # Parar a execuÃ§Ã£o


    with st.sidebar:
        st.title("â„¹ï¸ Painel de Controle")
        st.markdown("""
            Configure a anÃ¡lise de rotas aqui.

            **Funcionalidades:**
            - Visualize dados histÃ³ricos de velocidade
            - Detecte padrÃµes de trÃ¡fego (heatmap, decomposiÃ§Ã£o)
            - Obtenha insights automÃ¡ticos sobre a rota
            - PrevisÃ£o de velocidade para o futuro prÃ³ximo
            - Compare a anÃ¡lise entre diferentes rotas
        """)

        st.subheader("SeleÃ§Ã£o de Rotas")
        # Carregar nomes das rotas de forma eficiente (cached)
        all_route_names = get_all_route_names()
        if not all_route_names:
             st.warning("NÃ£o foi possÃ­vel carregar os nomes das rotas do banco de dados ou nÃ£o hÃ¡ rotas disponÃ­veis.")
             logging.warning("Nenhum nome de rota encontrado no banco de dados.") # Log detalhado
             st.stop() # Parar se nÃ£o houver rotas

        # Usar Ã­ndice para garantir que o selectbox nÃ£o quebre se o nome da rota mudar ou nÃ£o existir
        # Usar session_state para persistir a seleÃ§Ã£o de rota
        if "main_route_select" not in st.session_state or st.session_state.main_route_select not in all_route_names:
             st.session_state.main_route_select = all_route_names[0]

        try:
            default_main_route_index = all_route_names.index(st.session_state.main_route_select)
        except ValueError:
             default_main_route_index = 0

        route_name = st.selectbox(
            "Rota Principal:",
            all_route_names,
            index=default_main_route_index,
            key="main_route_select_box" # Use um key diferente do session_state key
        )
        # Atualiza o session_state key apÃ³s o selectbox
        st.session_state.main_route_select = route_name


        compare_enabled = st.checkbox("Comparar com outra rota", key="compare_checkbox")
        second_route = None
        if compare_enabled:
            available_for_comparison = [r for r in all_route_names if r != route_name]
            if available_for_comparison:
                 # Usar session_state para persistir a seleÃ§Ã£o da rota secundÃ¡ria
                 if "secondary_route_select" not in st.session_state or st.session_state.secondary_route_select not in available_for_comparison:
                      st.session_state.secondary_route_select = available_for_comparison[0]

                 try:
                     default_secondary_route_index = available_for_comparison.index(st.session_state.secondary_route_select)
                 except ValueError:
                      default_secondary_route_index = 0

                 second_route = st.selectbox(
                     "Rota SecundÃ¡ria:",
                     available_for_comparison,
                     index=default_secondary_route_index,
                     key="secondary_route_select_box" # Use um key diferente do session_state key
                 )
                 # Atualiza o session_state key
                 st.session_state.secondary_route_select = second_route

            else:
                 st.info("NÃ£o hÃ¡ outras rotas disponÃ­veis para comparaÃ§Ã£o.")
                 compare_enabled = False # Desabilita comparaÃ§Ã£o se nÃ£o houver outras rotas


        st.subheader("PerÃ­odo de AnÃ¡lise")
        # Usar um seletor de data por rota para flexibilidade na comparaÃ§Ã£o de perÃ­odos diferentes
        # Usar session_state para persistir as dates
        today = datetime.date.today()
        week_ago = today - datetime.timedelta(days=7)

        col_date1, col_date2 = st.columns(2)
        with col_date1:
             # Initialize session state for date range if not exists
             if f"date_range_{route_name}" not in st.session_state:
                 st.session_state[f"date_range_{route_name}"] = (week_ago, today)

             date_range_main_input = st.date_input(
                 f"PerÃ­odo para '{route_name}'",
                 value=st.session_state[f"date_range_{route_name}"],
                 max_value=today,
                 key=f"date_range_{route_name}_input" # Use um key diferente
             )
             # Update session state
             st.session_state[f"date_range_{route_name}"] = date_range_main_input
             date_range_main = st.session_state[f"date_range_{route_name}"] # Use o valor persistido


        date_range_secondary = None
        if compare_enabled and second_route:
             with col_date2:
                 # Initialize session state for date range if not exists
                 if f"date_range_{second_route}" not in st.session_state:
                      st.session_state[f"date_range_{second_route}"] = (week_ago, today)

                 date_range_secondary_input = st.date_input(
                      f"PerÃ­odo para '{second_route}'",
                      value=st.session_state[f"date_range_{second_route}"],
                      max_value=today,
                      key=f"date_range_{second_route}_input" # Use um key diferente
                 )
                 # Update session state
                 st.session_state[f"date_range_{second_route}"] = date_range_secondary_input
                 date_range_secondary = st.session_state[f"date_range_{second_route}"] # Use o valor persistido


        # Validar as dates
        if date_range_main and date_range_main[0] > date_range_main[1]:
            st.error("Data final da rota principal nÃ£o pode ser anterior Ã  data inicial")
            st.stop()
        if compare_enabled and date_range_secondary and date_range_secondary[0] > date_range_secondary[1]:
             st.error("Data final da rota secundÃ¡ria nÃ£o pode ser anterior Ã  data inicial.")
             st.stop()

        st.subheader("ConfiguraÃ§Ãµes ARIMA")
        # Adicionar seletor para o perÃ­odo sazonal (m)
        m_period_options = {
            "DiÃ¡rio (480 pontos @ 3min)": 480,
            "Semanal (3360 pontos @ 3min)": 3360,
            "Mensal (~14400 pontos @ 3min)": 14400 # Aproximado
        }
        selected_m_key = st.selectbox(
            "PerÃ­odo sazonal (m) para ARIMA:",
            list(m_period_options.keys()),
            index=0, # PadrÃ£o diÃ¡rio
            key="arima_m_select"
        )
        arima_m_period = m_period_options[selected_m_key]

        # Adicionar controle para o nÃºmero de passos da previsÃ£o
        forecast_steps = st.slider(f"Quantos pontos futuros prever ({arima_m_period} / freq 3min)?",
                                   min_value=1, max_value=4 * arima_m_period, # Permite prever atÃ© 4 ciclos
                                   value=arima_m_period // 2, # PadrÃ£o: meio ciclo
                                   step=int(arima_m_period / 10), # Passo razoÃ¡vel (1/10 do ciclo)
                                   key="forecast_steps_slider")
        st.info(f"PrevisÃ£o cobrirÃ¡ aproximadamente {forecast_steps * 3} minutos.")


    st.title("ðŸš€ AnÃ¡lise de Rotas Inteligente")
    st.markdown("Selecione as rotas e o perÃ­odo de anÃ¡lise no painel lateral.")

    routes_info = {}
    routes_to_process = [route_name]
    if compare_enabled and second_route:
        routes_to_process.append(second_route)

    # --- Carregamento e Processamento de Dados ---
    st.header("â³ Processando Dados...")
    processed_dfs = {} # DicionÃ¡rio para armazenar os DataFrames processados

    for route in routes_to_process:
        date_range = date_range_main if route == route_name else date_range_secondary
        if date_range is None: # Caso a comparaÃ§Ã£o esteja habilitada, mas a rota secundÃ¡ria nÃ£o tenha range
             continue

        # Converter objetos date para stringsYYYY-MM-DD para passar para get_data
        start_date_str = date_range[0].strftime('%Y-%m-%d')
        end_date_str = date_range[1].strftime('%Y-%m-%d')

        with st.spinner(f'Carregando e processando dados para {route} de {start_date_str} a {end_date_str}...'):
            # Carregar dados filtrando por nome da rota e perÃ­odo (cached)
            raw_df, error = get_data(
                start_date=start_date_str,
                end_date=end_date_str,
                route_name=route
            )

            if error:
                 st.error(f"Erro ao carregar dados para {route}: {error}")
                 logging.error(f"Erro ao carregar dados para {route}: {error}")
                 routes_info[route] = {'data': pd.DataFrame(), 'id': None, 'error': error}
                 continue # Pula para a prÃ³xima rota se houver erro

            if raw_df.empty:
                st.warning(f"Nenhum dado encontrado para a rota '{route}' no perÃ­odo de {start_date_str} a {end_date_str}. Por favor, ajuste o intervalo de dates.")
                logging.warning(f"Nenhum dado encontrado para a rota '{route}' no perÃ­odo {start_date_str} a {end_date_str}.")
                routes_info[route] = {'data': pd.DataFrame(), 'id': None}
                continue # Pula para a prÃ³xima rota

            # Adicionar indicador de qualidade dos dados (dados ausentes)
            total_records = len(raw_df)
            initial_nulls = raw_df['velocidade'].isnull().sum()
            initial_null_percentage = (initial_nulls / total_records) * 100 if total_records > 0 else 0
            st.metric(f"Dados Ausentes Inicialmente ({route})", f"{initial_null_percentage:.1f}%")

            # Obter o ID da rota (assumindo que hÃ¡ apenas um ID por nome no perÃ­odo selecionado)
            try:
                 route_id = raw_df['route_id'].iloc[0]
            except IndexError:
                 st.error(f"NÃ£o foi possÃ­vel obter o ID da rota para '{route}'. Dados insuficientes.")
                 logging.error(f"NÃ£o foi possÃ­vel obter ID da rota para '{route}'. DataFrame vazio ou sem route_id.")
                 routes_info[route] = {'data': pd.DataFrame(), 'id': None}
                 continue

            # Limpar e processar os dados
            processed_df = clean_data(raw_df)

            if processed_df.empty:
                 # Mensagem de warning jÃ¡ exibida dentro de clean_data se todos os valores forem nulos
                 routes_info[route] = {'data': pd.DataFrame(), 'id': None}
                 continue


            routes_info[route] = {
                'data': processed_df,
                'id': route_id
            }
            processed_dfs[route] = processed_df # Armazena para comparaÃ§Ã£o
        st.toast(f"Dados para {route} carregados e processados ({len(processed_df)} registros).", icon="âœ…") # Feedback com toast


    # --- SeÃ§Ã£o de VisualizaÃ§Ã£o ---

    # Se nÃ£o houver dados carregados para nenhuma rota, parar por aqui
    if not routes_info or all(info['data'].empty for info in routes_info.values()):
         st.info("Selecione as rotas e um perÃ­odo com dados disponÃ­veis no painel lateral para continuar.")
         return # Sai da funÃ§Ã£o main se nÃ£o houver dados


    st.header("ðŸ—ºï¸ VisualizaÃ§Ã£o GeogrÃ¡fica")
    # O mapa Ã© exibido por rota dentro do loop de processamento
    for route in routes_to_process:
         # Verifica se a rota foi carregada com sucesso e tem dados
         if route in routes_info and not routes_info[route]['data'].empty:
             route_id = routes_info[route]['id']
             # O expander deve ser dentro do loop para que cada rota tenha seu mapa
             with st.expander(f"Mapa da Rota: {route}", expanded=True):
                  # Obter coordenadas da rota (cached)
                  route_coords = get_route_coordinates(route_id)

                  if not route_coords.empty:
                      # Calcular bounds para centralizar o mapa
                      min_lat, max_lat = route_coords['latitude'].min(), route_coords['latitude'].max()
                      min_lon, max_lon = route_coords['longitude'].min(), route_coords['longitude'].max()

                      # Adicionar um pequeno buffer
                      lat_buffer = (max_lat - min_lat) * 0.05
                      lon_buffer = (max_lon - min_lon) * 0.05

                      center_lat = (max_lat + min_lat) / 2
                      center_lon = (max_lon + min_lon) / 2

                      # Determinar um zoom inicial razoÃ¡vel baseado nos bounds (heurÃ­stica simples)
                      # Calcula a extensÃ£o longitudinal e ajusta o zoom
                      lon_extent = max_lon - min_lon
                      lat_extent = max_lat - min_lat
                      # FÃ³rmula de zoom aproximada (ajuste conforme necessÃ¡rio)
                      if lon_extent > 0 and lat_extent > 0:
                         zoom_lon = 360 / lon_extent
                         zoom_lat = 180 / lat_extent
                         zoom = min(zoom_lon, zoom_lat) * 0.5 # Ajuste o fator (0.5)
                         zoom = min(max(zoom, 10), 15) # Limita o zoom entre 10 e 15
                      else:
                         zoom = 12 # Zoom padrÃ£o se a rota for muito pequena ou um ponto

                      fig = go.Figure(go.Scattermapbox(
                          mode="lines+markers",
                          lon=route_coords['longitude'],
                          lat=route_coords['latitude'],
                          marker={'size': 8, 'color': ACCENT_COLOR},
                          line=dict(width=4, color=PRIMARY_COLOR),
                          hovertext=[f"Ponto {i+1}" for i in range(len(route_coords))],
                          hoverinfo="text+lat+lon" # Mostra texto customizado + lat/lon no tooltip
                      ))

                      fig.update_layout(
                          mapbox={
                              'style': "carto-darkmatter", # Estilo de mapa que combina com o tema escuro
                              'center': {'lat': center_lat, 'lon': center_lon},
                              'zoom': zoom,
                              # bounds podem ser usados para focar na Ã¡rea
                              'bounds': {'west': min_lon - lon_buffer, 'east': max_lon + lon_buffer,
                                         'south': min_lat - lat_buffer, 'north': max_lat + lat_buffer}
                          },
                          margin={"r":0,"t":0,"l":0,"b":0},
                          height=500, # Altura do mapa
                          plot_bgcolor=SECONDARY_BACKGROUND_COLOR, # Fundo do plot
                          paper_bgcolor=SECONDARY_BACKGROUND_COLOR, # Fundo do papel (figura)
                          font=dict(color=TEXT_COLOR), # Cor da fonte global do grÃ¡fico
                          title=f"Mapa da Rota: {route}" # Adiciona tÃ­tulo ao mapa
                      )
                      st.plotly_chart(fig, use_container_width=True)
                  else:
                      st.warning(f"Nenhuma coordenada geogrÃ¡fica encontrada para a rota '{route}'. NÃ£o Ã© possÃ­vel exibir o mapa.")
         elif route in routes_info and 'error' in routes_info[route]:
              st.warning(f"Mapa nÃ£o disponÃ­vel para '{route}' devido a erro no carregamento de dados.")
         else:
             # Isso pode acontecer se compare_enabled for True mas a segunda rota nÃ£o puder ser carregada
             st.info(f"Dados insuficientes para exibir o mapa da rota '{route}'.")


    st.header("ðŸ“Š VisualizaÃ§Ã£o de Dados HistÃ³ricos")

    # --- ComparaÃ§Ã£o Visual de Dados HistÃ³ricos (GrÃ¡fico de Linha Plotly) ---
    if len(processed_dfs) > 0:
         st.subheader("ComparaÃ§Ã£o de Velocidade HistÃ³rica ao Longo do Tempo")
         fig_historical_comparison = go.Figure()

         colors = [PRIMARY_COLOR, ACCENT_COLOR] # Cores para as rotas

         for i, (r_name, r_df) in enumerate(processed_dfs.items()):
              if not r_df.empty:
                   fig_historical_comparison.add_trace(go.Scatter(
                       x=r_df['data'],
                       y=r_df['velocidade'],
                       mode='lines',
                       name=f'HistÃ³rico: {r_name}',
                       line=dict(color=colors[i % len(colors)], width=2) # Usa cores distintas
                   ))
              else:
                   st.info(f"Dados insuficientes para incluir '{r_name}' no grÃ¡fico de comparaÃ§Ã£o histÃ³rica.")


         if len(fig_historical_comparison.data) > 0: # Exibe apenas se houver pelo menos uma rota
              fig_historical_comparison.update_layout(
                  title='Velocidade HistÃ³rica ao Longo do Tempo',
                  xaxis_title="Data/Hora",
                  yaxis_title="Velocidade (km/h)",
                  hovermode='x unified',
                  plot_bgcolor=SECONDARY_BACKGROUND_COLOR,
                  paper_bgcolor=SECONDARY_BACKGROUND_COLOR,
                  font=dict(color=TEXT_COLOR),
                  title_font_color=TEXT_COLOR,
                  xaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                  yaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                  legend=dict(font=dict(color=TEXT_COLOR))
              )
              st.plotly_chart(fig_historical_comparison, use_container_width=True)
         elif compare_enabled:
              st.info("Dados insuficientes para realizar a comparaÃ§Ã£o histÃ³rica entre as rotas selecionadas.")


    # --- SeÃ§Ã£o de AnÃ¡lise Preditiva ---
    st.header("ðŸ“ˆ AnÃ¡lise Preditiva")
    for route in routes_to_process:
        # Verifica se a rota foi carregada com sucesso e tem dados processados
        if route in routes_info and not routes_info[route]['data'].empty:
            processed_df = routes_info[route]['data']
            route_id = routes_info[route]['id']

            # Expander para cada rota
            with st.expander(f"AnÃ¡lise para {route}", expanded=True):

                st.subheader("ðŸ§  Insights AutomÃ¡ticos")
                st.markdown(gerar_insights(processed_df))

                st.subheader("ðŸ“‰ DecomposiÃ§Ã£o Temporal")
                # Passa o df processado que clean_data retornou
                # Esta funÃ§Ã£o usa Matplotlib, a cor do tema Ã© configurada DENTRO dela.
                seasonal_decomposition_plot(processed_df)


                st.subheader("ðŸ”¥ Heatmap HorÃ¡rio por Dia da Semana")
                if not processed_df.empty:
                    pivot_table = processed_df.pivot_table(
                        index='day_of_week',
                        columns='hour',
                        values='velocidade',
                        aggfunc='mean'
                    )

                    # Reordenar dias da semana (em portuguÃªs)
                    dias_ordenados_eng = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                    dias_pt = ['Segunda', 'TerÃ§a', 'Quarta', 'Quinta', 'Sexta', 'SÃ¡bado', 'Domingo']
                    dia_mapping = dict(zip(dias_ordenados_eng, dias_pt))

                    # Reindexar a tabela pivotada para garantir a ordem dos dias
                    pivot_table = pivot_table.reindex(dias_ordenados_eng)
                    # Renomear o Ã­ndice para portuguÃªs
                    pivot_table.index = pivot_table.index.map(dia_mapping)


                    # --- Usar Matplotlib/Seaborn Heatmap ---
                    # Criar uma figura e eixos Matplotlib
                    fig_mpl, ax_mpl = plt.subplots(figsize=(12, 8)) # Tamanho da figura

                    # Gerar o heatmap usando Seaborn
                    sns.heatmap(
                        pivot_table,
                        annot=True,      # Mostrar os valores nas cÃ©lulas
                        fmt=".0f",       # Formatar os valores para 0 casas decimais (inteiro) <--- Corrigido para 0 casas decimais
                        cmap="viridis",  # Mapa de cores (similar ao Viridis do Plotly)
                        linewidths=.5,   # Adicionar linhas entre as cÃ©lulas para clareza
                        ax=ax_mpl        # Desenhar no eixo Matplotlib criado
                         # annot_kws={"color": TEXT_COLOR} # Opcional: cor da fonte da anotaÃ§Ã£o (pode prejudicar leitura)
                    )

                    # Configurar tÃ­tulos e labels dos eixos para o tema escuro
                    ax_mpl.set_title('Velocidade MÃ©dia por Dia da Semana e Hora', color=TEXT_COLOR)
                    ax_mpl.set_xlabel('Hora do Dia', color=TEXT_COLOR)
                    ax_mpl.set_ylabel('Dia da Semana', color=TEXT_COLOR)

                    # Configurar cor dos ticks dos eixos e fundo do plot
                    ax_mpl.tick_params(axis='x', colors=TEXT_COLOR)
                    ax_mpl.tick_params(axis='y', colors=TEXT_COLOR)
                    ax_mpl.set_facecolor(SECONDARY_BACKGROUND_COLOR) # Fundo da Ã¡rea do plot

                    # Configurar cor de fundo da figura inteira
                    fig_mpl.patch.set_facecolor(SECONDARY_BACKGROUND_COLOR) # Fundo da figura

                    # Configurar a cor da barra de cor (colorbar)
                    cbar = ax_mpl.collections[0].colorbar # Obter o objeto colorbar
                    if cbar:
                         cbar.ax.tick_params(colors=TEXT_COLOR) # Cor dos ticks
                         cbar.set_label('Velocidade MÃ©dia (km/h)', color=TEXT_COLOR) # Cor do label

                    # Exibir a figura Matplotlib no Streamlit
                    st.pyplot(fig_mpl)
                    plt.close(fig_mpl) # Fechar a figura para liberar memÃ³ria

                else:
                    st.info("Dados insuficientes para gerar o Heatmap.")


                st.subheader("ðŸ”® PrevisÃ£o de Velocidade (ARIMA)")

                # BotÃ£o para rodar a previsÃ£o (usa forecast_steps e arima_m_period definidos na sidebar)
                if st.button(f"Gerar PrevisÃ£o para {route}", key=f"generate_forecast_{route}"):
                     forecast_df = pd.DataFrame() # Initialize DataFrame

                     # --- Try/Except para a GeraÃ§Ã£o da PrevisÃ£o ARIMA ---
                     try:
                         st.info(f"Iniciando geraÃ§Ã£o da previsÃ£o ARIMA para {route} com perÃ­odo sazonal m={arima_m_period} e {forecast_steps} passos futuros...")
                         # Chamada da funÃ§Ã£o de previsÃ£o ARIMA (agora com exÃ³genas e m_period)
                         forecast_df = create_arima_forecast(processed_df, route_id, steps=forecast_steps, m_period=arima_m_period)

                         if not forecast_df.empty:
                             st.success(f"PrevisÃ£o gerada para os prÃ³ximos {forecast_steps * 3} minutos.")
                             st.toast("PrevisÃ£o gerada!", icon="âœ…") # Feedback com toast


                             # --- Try/Except para Plotar o GrÃ¡fico de PrevisÃ£o ---
                             try:
                                 st.info("Gerando grÃ¡fico de previsÃ£o...")
                                 fig_forecast = go.Figure()

                                 # Adiciona os dados histÃ³ricos
                                 fig_forecast.add_trace(go.Scatter(
                                     x=processed_df['data'],
                                     y=processed_df['velocidade'],
                                     mode='lines',
                                     name=f'HistÃ³rico: {route}', # Nome da rota no histÃ³rico
                                     line=dict(color=TEXT_COLOR, width=2) # Cor para o histÃ³rico
                                 ))

                                 # Adiciona a previsÃ£o
                                 fig_forecast.add_trace(go.Scatter(
                                     x=forecast_df['ds'],
                                     y=forecast_df['yhat'],
                                     mode='lines',
                                     name=f'PrevisÃ£o: {route}', # Nome da rota na previsÃ£o
                                     line=dict(color=PRIMARY_COLOR, width=3) # Cor primÃ¡ria para a previsÃ£o
                                 ))

                                 # Adiciona o intervalo de confianÃ§a
                                 fig_forecast.add_trace(go.Scatter(
                                     x=pd.concat([forecast_df['ds'], forecast_df['ds'][::-1]]), # Dates para o polÃ­gono (ida e volta)
                                     y=pd.concat([forecast_df['yhat_upper'], forecast_df['yhat_lower'][::-1]]), # Limites (superior e inferior invertido)
                                     fill='toself', # Preenche a Ã¡rea entre as duas linhas
                                     fillcolor='rgba(0, 175, 255, 0.2)', # Cor semi-transparente (similar ao PRIMARY_COLOR)
                                     line=dict(color='rgba(255,255,255,0)'), # Linha invisÃ­vel
                                     name=f'Intervalo de ConfianÃ§a 95% ({route})'
                                 ))

                                 # Configura o layout do grÃ¡fico de previsÃ£o
                                 fig_forecast.update_layout(
                                     title=f'PrevisÃ£o de Velocidade para {route}',
                                     xaxis_title="Data/Hora",
                                     yaxis_title="Velocidade (km/h)",
                                     hovermode='x unified', # Agrupa tooltips por eixo X
                                     plot_bgcolor=SECONDARY_BACKGROUND_COLOR,
                                     paper_bgcolor=SECONDARY_BACKGROUND_COLOR,
                                     font=dict(color=TEXT_COLOR),
                                     title_font_color=TEXT_COLOR,
                                     xaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                                     yaxis=dict(tickfont=dict(color=TEXT_COLOR), title_font_color=TEXT_COLOR),
                                     legend=dict(font=dict(color=TEXT_COLOR))
                                 )

                                 st.plotly_chart(fig_forecast, use_container_width=True)
                                 st.success("GrÃ¡fico de previsÃ£o gerado.")


                             except Exception as e:
                                 logging.exception("Erro ao gerar ou exibir o grÃ¡fico de previsÃ£o:") # Log detalhado
                                 st.error(f"Erro ao gerar ou exibir o grÃ¡fico de previsÃ£o: {e}")
                                 st.info("Verifique se hÃ¡ dados suficientes na previsÃ£o gerada ou se hÃ¡ problemas na configuraÃ§Ã£o do grÃ¡fico Plotly.")

                             # --- Try/Except para Salvar no Banco de Dados ---
                             # O botÃ£o de salvar sÃ³ aparece APÃ“S a previsÃ£o ser gerada e plotada
                             if st.button(f"Salvar PrevisÃ£o no Banco de Dados para {route}", key=f"save_forecast_{route}"):
                                  save_forecast_to_db(forecast_df)


                         else:
                             st.warning("PrevisÃ£o nÃ£o gerada ou DataFrame de previsÃ£o vazio. NÃ£o Ã© possÃ­vel exibir o grÃ¡fico ou salvar.")
                             st.toast("PrevisÃ£o falhou!", icon="âŒ") # Feedback com toast

                     except Exception as e:
                         logging.exception("Erro fatal durante a geraÃ§Ã£o da previsÃ£o ARIMA:") # Log detalhado
                         st.error(f"Erro fatal durante a geraÃ§Ã£o da previsÃ£o ARIMA: {e}")
                         st.info("Verifique os dados de entrada, a quantidade de dados, ou a configuraÃ§Ã£o do modelo ARIMA.")
                         st.toast("PrevisÃ£o falhou!", icon="âŒ") # Feedback com toast


                # Mensagem inicial antes de gerar a previsÃ£o
                elif f"generate_forecast_{route}" not in st.session_state:
                    st.info("Configure o perÃ­odo sazonal e os passos futuros na sidebar e clique em 'Gerar PrevisÃ£o'.")


        # Adiciona uma linha separadora entre as anÃ¡lises de rotas se houver mais de uma
        if len(routes_to_process) > 1 and routes_to_process.index(route) < len(routes_to_process) - 1:
            st.markdown("---") # Linha horizontal

    # Mensagem final caso nenhuma rota tenha dados
    if not routes_info or all(info['data'].empty for info in routes_info.values()):
         st.info("Nenhuma anÃ¡lise exibida. Selecione rotas com dados disponÃ­veis.")


# --- Executa o aplicativo Streamlit ---
if __name__ == "__main__":
    main()